{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c44d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 22:24:32.043738: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import PatchTSTForPrediction\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96672c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"coin\"\n",
    "\n",
    "output_dir = \"saved_models\"\n",
    "log_dir = os.path.join('logstf', data)\n",
    "\n",
    "loss_name = \"mae\"\n",
    "\n",
    "num_train_epochs = 300\n",
    "model_num = 1\n",
    "model_path = \"./saved_models\"\n",
    "learning_rate = 5e-6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3474e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## target domain\n",
    "target_X = pd.read_csv(f\"../data/{data}/train_input_7.csv\").iloc[:, 1:].values.astype(np.float32)\n",
    "target_y = pd.read_csv(f\"../data/{data}/train_output_7.csv\").iloc[:, 1:].values.astype(np.float32)\n",
    "\n",
    "target_X_val = target_X[-round(target_X.shape[0] * 0.2):, :].astype(np.float32)\n",
    "target_y_val = target_y[-round(target_y.shape[0] * 0.2):].astype(np.float32)\n",
    "target_X = target_X[:-round(target_X.shape[0] * 0.2), :].astype(np.float32)\n",
    "target_y = target_y[:-round(target_y.shape[0] * 0.2)].astype(np.float32)\n",
    "\n",
    "test_X  = pd.read_csv(f\"../data/{data}/val_input_7.csv\").iloc[:, 1:].values.astype(np.float32)\n",
    "test_y  = pd.read_csv(f\"../data/{data}/val_output_7.csv\").iloc[:, 1:].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10be638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_dataset(X, y):\n",
    "    X, y = torch.tensor(X), torch.tensor(y)\n",
    "    X = X.reshape(-1, X.shape[1], 1)\n",
    "    y = y.reshape(-1, y.shape[1], 1)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X, y)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_dataset = array_to_dataset(target_X, target_y)\n",
    "val_dataset = array_to_dataset(target_X_val, target_y_val)\n",
    "test_dataset = array_to_dataset(test_X, test_y)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 8, shuffle = True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = 64)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "561645fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, model_num+1):\n",
    "    current_path = os.path.join(model_path, f\"model_{loss_name}_{k}.pth\")\n",
    "\n",
    "    backbone_model = PatchTSTForPrediction.from_pretrained(os.path.join(model_path, \"PatchTSTBackbone\")).to(device)\n",
    "    backbone_model.load_state_dict(torch.load(current_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "694dc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout = 0.05, max_len = 5000, **kwargs):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p = dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2)) * (-np.log(10000.0) / d_model)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(torch.tensor(position * div_term))\n",
    "        pe[:, 1::2] = torch.cos(torch.tensor(position * div_term))\n",
    "        pe = pe.unsqueeze(0)    ## (1, max_len, d_model)\n",
    "        \n",
    "        self.register_buffer(\"pe\", pe)  ## 불변값. 학습되지 않음. tf.constant\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c8b3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerHead(torch.nn.Module):\n",
    "    def __init__(self, d_model, nlayers, nhead, dropout, iw, ow, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_adapter = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, d_model // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(d_model // 2, d_model),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(d_model, dropout)    ## patch만 position encoding\n",
    "\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            torch.nn.ModuleDict({\n",
    "                \"attn\": torch.nn.MultiheadAttention(embed_dim = d_model, num_heads = nhead, dropout = dropout, batch_first = True),\n",
    "                \"norm1\": torch.nn.LayerNorm(d_model, eps = 1e-6),\n",
    "                \"ffn1\": torch.nn.Linear(d_model, d_model),\n",
    "                \"relu\": torch.nn.ReLU(),\n",
    "                \"ffn2\": torch.nn.Linear(d_model, d_model),\n",
    "                \"norm2\": torch.nn.LayerNorm(d_model, eps = 1e-6)\n",
    "            }) for _ in range(nlayers)\n",
    "        ])\n",
    "\n",
    "        self.outlayer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(d_model, d_model // 2),         ## (B, 7, 42)\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten(),                             ## (B, 7*42 = 294). squeeze 역할\n",
    "            torch.nn.Linear(iw * (d_model // 2), 128),      ## (B, 128)\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, ow) ## (B, 24)\n",
    "        )\n",
    "\n",
    "    def forward(self, patchTSToutput):\n",
    "        x = patchTSToutput.last_hidden_state.squeeze(1) ## (B, 7, 256)\n",
    "        x = self.input_adapter(x)                       ## (B, 7, 84)\n",
    "        x = self.pos_encoding(x)                        ## (B, 7, 84)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            attn_output, _ = layer[\"attn\"](x, x, x)\n",
    "            x = layer[\"norm1\"](x + attn_output)\n",
    "\n",
    "            ffn_output = layer[\"relu\"](layer[\"ffn1\"](x))\n",
    "            ffn_output = layer[\"ffn2\"](ffn_output)\n",
    "            x = layer[\"norm2\"](x + ffn_output)\n",
    "\n",
    "        outputs = self.outlayer(x)\n",
    "        outputs = outputs.unsqueeze(2)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6144f5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2085343/4015960496.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pe[:, 0::2] = torch.sin(torch.tensor(position * div_term))\n",
      "/tmp/ipykernel_2085343/4015960496.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pe[:, 1::2] = torch.cos(torch.tensor(position * div_term))\n"
     ]
    }
   ],
   "source": [
    "model_instance = torch.nn.Sequential(\n",
    "    backbone_model.model,\n",
    "    TransformerHead(\n",
    "        d_model = 84, nlayers = 4, nhead = 4, dropout = 0.2,\n",
    "        iw = 7, ow = target_y.shape[1], input_dim = 256\n",
    "    )\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2179b55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 | Train Loss: 26687.898170\t\t Val Loss: 4864.021973\n",
      "Epoch 2/300 | Train Loss: 26601.788260\t\t Val Loss: 4851.244629\n",
      "Epoch 3/300 | Train Loss: 26571.177106\t\t Val Loss: 4835.811523\n",
      "Epoch 4/300 | Train Loss: 26639.496040\t\t Val Loss: 4817.316895\n",
      "Epoch 5/300 | Train Loss: 26908.564105\t\t Val Loss: 4795.330078\n",
      "Epoch 6/300 | Train Loss: 26547.277544\t\t Val Loss: 4769.195312\n",
      "Epoch 7/300 | Train Loss: 26243.979964\t\t Val Loss: 4736.920898\n",
      "Epoch 8/300 | Train Loss: 26354.680236\t\t Val Loss: 4700.019043\n",
      "Epoch 9/300 | Train Loss: 26221.689721\t\t Val Loss: 4659.393066\n",
      "Epoch 10/300 | Train Loss: 26100.688075\t\t Val Loss: 4615.312988\n",
      "Epoch 11/300 | Train Loss: 26321.821236\t\t Val Loss: 4568.777344\n",
      "Epoch 12/300 | Train Loss: 25816.500375\t\t Val Loss: 4518.379395\n",
      "Epoch 13/300 | Train Loss: 25804.163889\t\t Val Loss: 4464.913574\n",
      "Epoch 14/300 | Train Loss: 25733.976589\t\t Val Loss: 4408.053223\n",
      "Epoch 15/300 | Train Loss: 25769.363830\t\t Val Loss: 4346.791504\n",
      "Epoch 16/300 | Train Loss: 25325.826881\t\t Val Loss: 4280.938965\n",
      "Epoch 17/300 | Train Loss: 25226.912216\t\t Val Loss: 4211.207520\n",
      "Epoch 18/300 | Train Loss: 25077.450409\t\t Val Loss: 4136.652344\n",
      "Epoch 19/300 | Train Loss: 25521.556534\t\t Val Loss: 4057.820557\n",
      "Epoch 20/300 | Train Loss: 25088.697011\t\t Val Loss: 3973.806396\n",
      "Epoch 21/300 | Train Loss: 24466.918785\t\t Val Loss: 3885.631348\n",
      "Epoch 22/300 | Train Loss: 24247.210536\t\t Val Loss: 3795.217285\n",
      "Epoch 23/300 | Train Loss: 23893.031670\t\t Val Loss: 3699.613525\n",
      "Epoch 24/300 | Train Loss: 23797.266281\t\t Val Loss: 3601.773438\n",
      "Epoch 25/300 | Train Loss: 23477.219847\t\t Val Loss: 3499.389648\n",
      "Epoch 26/300 | Train Loss: 23366.720248\t\t Val Loss: 3394.602783\n",
      "Epoch 27/300 | Train Loss: 23076.467921\t\t Val Loss: 3285.356934\n",
      "Epoch 28/300 | Train Loss: 22810.502435\t\t Val Loss: 3173.699219\n",
      "Epoch 29/300 | Train Loss: 22428.306855\t\t Val Loss: 3059.250732\n",
      "Epoch 30/300 | Train Loss: 22622.674216\t\t Val Loss: 2943.687256\n",
      "Epoch 31/300 | Train Loss: 22404.674671\t\t Val Loss: 2825.294922\n",
      "Epoch 32/300 | Train Loss: 21458.589188\t\t Val Loss: 2703.990967\n",
      "Epoch 33/300 | Train Loss: 21201.131007\t\t Val Loss: 2583.928223\n",
      "Epoch 34/300 | Train Loss: 20912.017993\t\t Val Loss: 2461.308594\n",
      "Epoch 35/300 | Train Loss: 20404.066707\t\t Val Loss: 2339.665771\n",
      "Epoch 36/300 | Train Loss: 20410.781096\t\t Val Loss: 2218.429199\n",
      "Epoch 37/300 | Train Loss: 19857.055096\t\t Val Loss: 2095.872803\n",
      "Epoch 38/300 | Train Loss: 19711.385475\t\t Val Loss: 1975.051392\n",
      "Epoch 39/300 | Train Loss: 19032.104840\t\t Val Loss: 1853.870483\n",
      "Epoch 40/300 | Train Loss: 18542.457807\t\t Val Loss: 1736.838501\n",
      "Epoch 41/300 | Train Loss: 18281.880940\t\t Val Loss: 1620.979614\n",
      "Epoch 42/300 | Train Loss: 17758.657474\t\t Val Loss: 1507.343140\n",
      "Epoch 43/300 | Train Loss: 17351.500689\t\t Val Loss: 1399.790039\n",
      "Epoch 44/300 | Train Loss: 16937.245706\t\t Val Loss: 1293.587891\n",
      "Epoch 45/300 | Train Loss: 16604.685072\t\t Val Loss: 1192.742798\n",
      "Epoch 46/300 | Train Loss: 16282.510782\t\t Val Loss: 1096.271118\n",
      "Epoch 47/300 | Train Loss: 15829.413066\t\t Val Loss: 1003.853027\n",
      "Epoch 48/300 | Train Loss: 15503.675882\t\t Val Loss: 918.000000\n",
      "Epoch 49/300 | Train Loss: 15020.095509\t\t Val Loss: 837.668091\n",
      "Epoch 50/300 | Train Loss: 14643.007291\t\t Val Loss: 764.485168\n",
      "Epoch 51/300 | Train Loss: 14157.623602\t\t Val Loss: 697.686035\n",
      "Epoch 52/300 | Train Loss: 13791.383093\t\t Val Loss: 638.350586\n",
      "Epoch 53/300 | Train Loss: 13250.309039\t\t Val Loss: 587.649597\n",
      "Epoch 54/300 | Train Loss: 12969.218553\t\t Val Loss: 545.443237\n",
      "Epoch 55/300 | Train Loss: 12566.102074\t\t Val Loss: 512.860474\n",
      "Epoch 56/300 | Train Loss: 12062.067868\t\t Val Loss: 489.389832\n",
      "Epoch 57/300 | Train Loss: 11869.453593\t\t Val Loss: 475.938446\n",
      "Epoch 58/300 | Train Loss: 11264.350548\t\t Val Loss: 472.508392\n",
      "Epoch 59/300 | Train Loss: 10953.594265\t\t Val Loss: 479.407837\n",
      "Epoch 60/300 | Train Loss: 10512.610830\t\t Val Loss: 497.615936\n",
      "Epoch 61/300 | Train Loss: 10161.809477\t\t Val Loss: 525.688171\n",
      "Epoch 62/300 | Train Loss: 9847.580008\t\t Val Loss: 565.497864\n",
      "Epoch 63/300 | Train Loss: 9605.042999\t\t Val Loss: 616.713074\n",
      "Epoch 64/300 | Train Loss: 9136.384236\t\t Val Loss: 680.567383\n",
      "Epoch 65/300 | Train Loss: 8777.469869\t\t Val Loss: 753.841675\n",
      "Epoch 66/300 | Train Loss: 8507.890204\t\t Val Loss: 838.364441\n",
      "Epoch 67/300 | Train Loss: 8358.314604\t\t Val Loss: 934.127563\n",
      "Epoch 68/300 | Train Loss: 7938.396444\t\t Val Loss: 1044.422974\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model_instance.parameters(), lr = learning_rate)\n",
    "log_data = []\n",
    "\n",
    "if loss_name == \"mse\":\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "elif loss_name == \"mae\":\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "# elif loss_name\n",
    "\n",
    "## early stopping\n",
    "PATIENCE = 10\n",
    "best_val_loss = np.inf\n",
    "patience_counter = 0\n",
    "\n",
    "for epoc in range(num_train_epochs):\n",
    "    model_instance.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model_instance(X)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    model_instance.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        yys = []\n",
    "        yyhats = []\n",
    "\n",
    "        for XX, yy in val_dataloader:\n",
    "            XX = XX.to(device)\n",
    "            yys.append(yy.to(device))\n",
    "            yyhats.append(model_instance(XX))\n",
    "\n",
    "        yyhat = torch.concat(yyhats)\n",
    "        yy = torch.concat(yys)\n",
    "\n",
    "        val_loss = loss_fn(yyhat, yy)\n",
    "\n",
    "    print(f\"Epoch {epoc+1}/{num_train_epochs} | Train Loss: {avg_train_loss:.6f}\\t\\t Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    log_data.append({\"epoch\": epoc, \"loss\": avg_train_loss, \"eval_loss\": val_loss.item()})\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state_dict = model_instance.state_dict()   ## 저장 없이 결과물만 산출...\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= PATIENCE:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f6c1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    yys = []\n",
    "    yyhats = []\n",
    "\n",
    "    for XX, yy in test_dataloader:\n",
    "        XX = XX.to(device)\n",
    "        yys.append(yy.to(device))\n",
    "        yyhats.append(model_instance(XX))\n",
    "\n",
    "    yyhat = torch.concat(yyhats)\n",
    "    yy = torch.concat(yys)\n",
    "\n",
    "    test_loss = loss_fn(yyhat, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab49e291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE: 23.462501525878906\n",
      "test MAE: 19.19106101989746\n",
      "test SMAPE: 23.6146297454834\n"
     ]
    }
   ],
   "source": [
    "mseLoss = torch.nn.MSELoss()\n",
    "maeLoss = torch.nn.L1Loss()\n",
    "\n",
    "def smape(yy, yyhat):\n",
    "    numerator = 100*abs(yy - yyhat)\n",
    "    denominator = (abs(yy) + abs(yyhat))/2\n",
    "    smape = torch.mean(numerator / denominator)\n",
    "    return smape\n",
    "\n",
    "print(f\"test RMSE: {torch.sqrt(mseLoss(yyhat, yy))}\")\n",
    "print(f\"test MAE: {maeLoss(yyhat, yy)}\")\n",
    "print(f\"test SMAPE: {smape(yy, yyhat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f94ebff",
   "metadata": {},
   "source": [
    "> 망함. 헤드 아키텍쳐가 너무 복잡한 것 같은데? 헤드를 거의 새로 학습시키는 수준...\n",
    ">\n",
    "> 그냥 기존 아키텍쳐를 최대한 활용할 수 있는 게 가장 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ddab20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
