{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26c44d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import PatchTSTForPrediction\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96672c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"coin\"\n",
    "\n",
    "output_dir = \"saved_models\"\n",
    "log_dir = os.path.join('logstf', data)\n",
    "\n",
    "loss_name = \"SMAPE\"\n",
    "\n",
    "num_train_epochs = 300\n",
    "model_num = 1\n",
    "model_path = \"./saved_models\"\n",
    "learning_rate = 1e-6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e10038dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## target domain\n",
    "target_X = pd.read_csv(f\"../data/{data}/train_input_7.csv\").iloc[:, 1:].values.astype(np.float32)\n",
    "target_y = pd.read_csv(f\"../data/{data}/train_output_7.csv\").iloc[:, 1:].values.astype(np.float32)\n",
    "\n",
    "target_X_val = target_X[-round(target_X.shape[0] * 0.2):, :].astype(np.float32)\n",
    "target_y_val = target_y[-round(target_y.shape[0] * 0.2):].astype(np.float32)\n",
    "target_X = target_X[:-round(target_X.shape[0] * 0.2), :].astype(np.float32)\n",
    "target_y = target_y[:-round(target_y.shape[0] * 0.2)].astype(np.float32)\n",
    "\n",
    "test_X  = pd.read_csv(f\"../data/{data}/val_input_7.csv\").iloc[:, 1:].values.astype(np.float32)\n",
    "test_y  = pd.read_csv(f\"../data/{data}/val_output_7.csv\").iloc[:, 1:].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b4f2243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_dataset(X, y):\n",
    "    X, y = torch.tensor(X), torch.tensor(y)\n",
    "    X = X.reshape(-1, X.shape[1], 1)\n",
    "    y = y.reshape(-1, y.shape[1], 1)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X, y)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_dataset = array_to_dataset(target_X, target_y)\n",
    "val_dataset = array_to_dataset(target_X_val, target_y_val)\n",
    "test_dataset = array_to_dataset(test_X, test_y)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 8, shuffle = True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = 64)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "887f2cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, model_num+1):\n",
    "    current_path = os.path.join(model_path, f\"model_{loss_name}_{k}.pth\")\n",
    "\n",
    "    backbone_model = PatchTSTForPrediction.from_pretrained(os.path.join(model_path, \"PatchTSTBackbone\")).to(device)\n",
    "    backbone_model.load_state_dict(torch.load(current_path))    ## 구조 변경 없이 그대로 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef05faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(yhat, y):\n",
    "    numerator = 100*torch.abs(y - yhat)\n",
    "    denominator = (torch.abs(y) + torch.abs(yhat))/2\n",
    "    smape = torch.mean(numerator / denominator)\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19fe7d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 | Train Loss: 3.882582\t\t Val Loss: 2.746786\n",
      "Epoch 2/300 | Train Loss: 3.724143\t\t Val Loss: 2.697295\n",
      "Epoch 3/300 | Train Loss: 3.630796\t\t Val Loss: 2.676523\n",
      "Epoch 4/300 | Train Loss: 3.546190\t\t Val Loss: 2.659863\n",
      "Epoch 5/300 | Train Loss: 3.461951\t\t Val Loss: 2.638196\n",
      "Epoch 6/300 | Train Loss: 3.426297\t\t Val Loss: 2.651755\n",
      "Epoch 7/300 | Train Loss: 3.358912\t\t Val Loss: 2.652848\n",
      "Epoch 8/300 | Train Loss: 3.261051\t\t Val Loss: 2.643697\n",
      "Epoch 9/300 | Train Loss: 3.271560\t\t Val Loss: 2.654185\n",
      "Epoch 10/300 | Train Loss: 3.218434\t\t Val Loss: 2.664256\n",
      "Epoch 11/300 | Train Loss: 3.142867\t\t Val Loss: 2.648431\n",
      "Epoch 12/300 | Train Loss: 3.113573\t\t Val Loss: 2.661589\n",
      "Epoch 13/300 | Train Loss: 3.077688\t\t Val Loss: 2.654392\n",
      "Epoch 14/300 | Train Loss: 3.048001\t\t Val Loss: 2.612900\n",
      "Epoch 15/300 | Train Loss: 2.999415\t\t Val Loss: 2.649789\n",
      "Epoch 16/300 | Train Loss: 2.990046\t\t Val Loss: 2.674138\n",
      "Epoch 17/300 | Train Loss: 2.947379\t\t Val Loss: 2.649256\n",
      "Epoch 18/300 | Train Loss: 2.924937\t\t Val Loss: 2.633074\n",
      "Epoch 19/300 | Train Loss: 2.901783\t\t Val Loss: 2.650935\n",
      "Epoch 20/300 | Train Loss: 2.923304\t\t Val Loss: 2.665222\n",
      "Epoch 21/300 | Train Loss: 2.834754\t\t Val Loss: 2.681702\n",
      "Epoch 22/300 | Train Loss: 2.837077\t\t Val Loss: 2.628804\n",
      "Epoch 23/300 | Train Loss: 2.778518\t\t Val Loss: 2.640175\n",
      "Epoch 24/300 | Train Loss: 2.848486\t\t Val Loss: 2.663721\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(backbone_model.parameters(), lr = learning_rate)\n",
    "log_data = []\n",
    "\n",
    "if loss_name == \"mse\":\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "elif loss_name == \"mae\":\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "elif loss_name == \"SMAPE\":\n",
    "    loss_fn = SMAPE\n",
    "\n",
    "## early stopping\n",
    "PATIENCE = 10\n",
    "best_val_loss = np.inf\n",
    "patience_counter = 0\n",
    "\n",
    "for epoc in range(num_train_epochs):\n",
    "    backbone_model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        yhat = backbone_model(X).prediction_outputs\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()*X.shape[0]\n",
    "\n",
    "    avg_train_loss = total_train_loss/len(train_dataloader.dataset)\n",
    "\n",
    "    backbone_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        yys = []\n",
    "        yyhats = []\n",
    "\n",
    "        for XX, yy in val_dataloader:\n",
    "            XX = XX.to(device)\n",
    "            yys.append(yy.to(device))\n",
    "            yyhats.append(backbone_model(XX).prediction_outputs)\n",
    "\n",
    "        yyhat = torch.concat(yyhats)\n",
    "        yy = torch.concat(yys)\n",
    "\n",
    "        val_loss = loss_fn(yyhat, yy).item()\n",
    "\n",
    "    print(f\"Epoch {epoc+1}/{num_train_epochs} | Train Loss: {avg_train_loss:.6f}\\t\\t Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    log_data.append({\"epoch\": epoc, \"loss\": avg_train_loss, \"eval_loss\": val_loss})\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state_dict = backbone_model.state_dict()   ## 저장 없이 결과물만 산출...\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= PATIENCE:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9588fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(151.20018), np.float32(67.18279), np.float32(75.756134))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_y.mean(), target_y_val.mean(), test_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f7c0662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d79d2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(log_data).to_csv(os.path.join(log_dir, f\"transfer_{loss_name}_lr{learning_rate}_run{1}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a53776a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yys = []\n",
    "    yyhats = []\n",
    "\n",
    "    for XX, yy in test_dataloader:\n",
    "        XX = XX.to(device)\n",
    "        yys.append(yy.to(device))\n",
    "        yyhats.append(backbone_model(XX).prediction_outputs)\n",
    "\n",
    "    yyhat = torch.concat(yyhats)\n",
    "    yy = torch.concat(yys)\n",
    "\n",
    "    test_loss = loss_fn(yyhat, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a074783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE: 3.8674254417419434\n",
      "test MAE: 1.5500025749206543\n",
      "test SMAPE: 2.1890923976898193\n"
     ]
    }
   ],
   "source": [
    "mseLoss = torch.nn.MSELoss()\n",
    "maeLoss = torch.nn.L1Loss()\n",
    "\n",
    "def smape(yy, yyhat):\n",
    "    numerator = 100*abs(yy - yyhat)\n",
    "    denominator = (abs(yy) + abs(yyhat))/2\n",
    "    smape = torch.mean(numerator / denominator)\n",
    "    return smape\n",
    "\n",
    "print(f\"test RMSE: {torch.sqrt(mseLoss(yyhat, yy))}\")\n",
    "print(f\"test MAE: {maeLoss(yyhat, yy)}\")\n",
    "print(f\"test SMAPE: {smape(yy, yyhat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e57e669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yys = []\n",
    "    yyhats = []\n",
    "\n",
    "    for XX, yy in test_dataloader:\n",
    "        XX = XX.to(device)\n",
    "        yys.append(yy.to(device))\n",
    "        yyhats.append(backbone_model(XX).prediction_outputs)\n",
    "\n",
    "    yyhat = torch.concat(yyhats)\n",
    "    yy = torch.concat(yys)\n",
    "\n",
    "    test_loss = loss_fn(yyhat, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bae6bd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE: 3.8674254417419434\n",
      "test MAE: 1.5500025749206543\n",
      "test SMAPE: 2.1890923976898193\n"
     ]
    }
   ],
   "source": [
    "mseLoss = torch.nn.MSELoss()\n",
    "maeLoss = torch.nn.L1Loss()\n",
    "\n",
    "def smape(yy, yyhat):\n",
    "    numerator = 100*abs(yy - yyhat)\n",
    "    denominator = (abs(yy) + abs(yyhat))/2\n",
    "    smape = torch.mean(numerator / denominator)\n",
    "    return smape\n",
    "\n",
    "print(f\"test RMSE: {torch.sqrt(mseLoss(yyhat, yy))}\")\n",
    "print(f\"test MAE: {maeLoss(yyhat, yy)}\")\n",
    "print(f\"test SMAPE: {smape(yy, yyhat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70934ad",
   "metadata": {},
   "source": [
    "> ????????? 그냥 단순한 Linear head인데..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1dfa4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchTSTPredictionHead(\n",
       "  (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "  (projection): Linear(in_features=1792, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb3448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
