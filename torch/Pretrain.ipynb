{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4991e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 19:02:56.928551: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    PatchTSTConfig, PatchTSTForPrediction,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"coin\"\n",
    "output_dir = \"./saved_models\"\n",
    "LOG_DIR = \"./logstf/coin\"\n",
    "loss_name = \"mse\"\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7961096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## target domain\n",
    "target_X = pd.read_csv(f\"../data/{data}/train_input_7.csv\").iloc[:, 1:].values.astype(np.float32)\n",
    "\n",
    "np.random.seed(2)\n",
    "random_indices1 = np.random.choice(pd.read_csv(\"../data/M4_train.csv\").iloc[:, (1):].index,\n",
    "                                   size=target_X.shape[0] * 20, replace=True)\n",
    "\n",
    "X_data = pd.read_csv(\"../data/M4_train.csv\").iloc[:, 1 + (24 * 0):].loc[random_indices1].values.astype(np.float32)\n",
    "y_data = pd.read_csv(\"../data/M4_test.csv\").iloc[:, 1:].loc[random_indices1].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2836e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSTconfig = PatchTSTConfig(\n",
    "    num_input_channels = 1,\n",
    "    context_length = X_data.shape[1],\n",
    "    prediction_length = y_data.shape[1],\n",
    "\n",
    "    patch_length = 16,\n",
    "    patch_stride = 16,\n",
    "    d_model = 256,\n",
    "    num_attention_heads = 8,\n",
    "    num_hidden_layers = 8,\n",
    "    ffn_dim = 512,\n",
    "    dropout = 0.2,\n",
    "    head_dropout = 0.2,\n",
    "    pooling_type = None,\n",
    "    channel_attention = False,\n",
    "    scaling = \"std\",\n",
    "    loss = loss_name,\n",
    "    pre_norm = True,\n",
    "    do_mask_input = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fa63645",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PatchTSTForPrediction(TSTconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91eb7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "select = np.random.choice(len(X_data), size=len(X_data), replace=True)\n",
    "X_bootstrap = X_data[select]\n",
    "y_bootstrap = y_data[select]\n",
    "\n",
    "val_split_index = int(len(X_bootstrap) * 0.8)\n",
    "X_train, X_valid = X_bootstrap[:val_split_index], X_bootstrap[val_split_index:]\n",
    "y_train, y_valid = y_bootstrap[:val_split_index], y_bootstrap[val_split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4812b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hf_dataset(x, y):\n",
    "    x_list = [s[..., np.newaxis] for s in x]    ## (N, 168) -> (N, 168, 1)\n",
    "    y_list = [s[..., np.newaxis] for s in y]    ## (N, 24) -> (N, 24, 1)\n",
    "\n",
    "    data_dict = {\n",
    "        \"past_values\": x_list,\n",
    "        \"future_values\": y_list\n",
    "    }\n",
    "\n",
    "    return Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd3e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_hf_dataset(X_train, y_train)\n",
    "test_dataset = create_hf_dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "226c7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    overwrite_output_dir = True,\n",
    "    learning_rate = learning_rate,\n",
    "    num_train_epochs = 2000,\n",
    "    do_eval = True,\n",
    "    eval_strategy = \"epoch\",\n",
    "    per_device_train_batch_size = 256,\n",
    "    per_device_eval_batch_size = 256,\n",
    "    dataloader_num_workers = 16,\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    save_total_limit = 1,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_loss\",\n",
    "    greater_is_better = False,\n",
    "    label_names = [\"future_values\"]\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience = 10,\n",
    "    early_stopping_threshold = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "957e3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    callbacks = [early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08a252b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3818' max='92000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3818/92000 04:33 < 1:45:18, 13.96 it/s, Epoch 83/2000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1585352.000000</td>\n",
       "      <td>1517283.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>961546.869600</td>\n",
       "      <td>799644.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>833653.913000</td>\n",
       "      <td>720968.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>755879.043500</td>\n",
       "      <td>655159.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>717851.130400</td>\n",
       "      <td>606954.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>658094.000000</td>\n",
       "      <td>590459.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>682773.521700</td>\n",
       "      <td>582107.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>593815.782600</td>\n",
       "      <td>592338.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>574113.478300</td>\n",
       "      <td>594332.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>507859.782600</td>\n",
       "      <td>526616.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>489233.478300</td>\n",
       "      <td>519847.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>450972.695700</td>\n",
       "      <td>517895.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>466018.652200</td>\n",
       "      <td>567174.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>458640.782600</td>\n",
       "      <td>553112.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>416272.695700</td>\n",
       "      <td>548193.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>418079.043500</td>\n",
       "      <td>499135.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>404022.652200</td>\n",
       "      <td>503743.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>376135.478300</td>\n",
       "      <td>477822.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>364076.543500</td>\n",
       "      <td>461972.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>353474.000000</td>\n",
       "      <td>513624.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>354574.304300</td>\n",
       "      <td>476923.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>348836.456500</td>\n",
       "      <td>427184.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>327627.869600</td>\n",
       "      <td>507938.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>324246.043500</td>\n",
       "      <td>439171.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>332746.521700</td>\n",
       "      <td>410822.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>304328.391300</td>\n",
       "      <td>430088.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>302419.978300</td>\n",
       "      <td>422674.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>274760.021700</td>\n",
       "      <td>435322.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>278188.826100</td>\n",
       "      <td>525179.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>293155.173900</td>\n",
       "      <td>483367.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>274204.195700</td>\n",
       "      <td>551038.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>267870.108700</td>\n",
       "      <td>388164.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>258551.956500</td>\n",
       "      <td>401127.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>255061.608700</td>\n",
       "      <td>382057.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>263000.760900</td>\n",
       "      <td>411620.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>248533.369600</td>\n",
       "      <td>391538.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>224112.608700</td>\n",
       "      <td>403119.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>226261.065200</td>\n",
       "      <td>402744.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>214576.739100</td>\n",
       "      <td>461261.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>221017.021700</td>\n",
       "      <td>379756.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>232310.282600</td>\n",
       "      <td>416623.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>214168.673900</td>\n",
       "      <td>354129.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>211101.217400</td>\n",
       "      <td>398051.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>210894.869600</td>\n",
       "      <td>366691.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>205037.043500</td>\n",
       "      <td>353912.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>199052.304300</td>\n",
       "      <td>370154.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>185474.760900</td>\n",
       "      <td>357601.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>183969.739100</td>\n",
       "      <td>359866.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>188521.500000</td>\n",
       "      <td>336048.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>180094.087000</td>\n",
       "      <td>353912.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>183300.195700</td>\n",
       "      <td>391005.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>170077.282600</td>\n",
       "      <td>348163.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>162576.739100</td>\n",
       "      <td>343158.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>165230.271700</td>\n",
       "      <td>344582.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>169548.543500</td>\n",
       "      <td>327397.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>165433.717400</td>\n",
       "      <td>327733.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>160926.087000</td>\n",
       "      <td>330033.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>155577.032600</td>\n",
       "      <td>338953.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>157054.195700</td>\n",
       "      <td>314249.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>151694.597800</td>\n",
       "      <td>336542.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>146217.119600</td>\n",
       "      <td>306051.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>152200.228300</td>\n",
       "      <td>347925.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>149563.532600</td>\n",
       "      <td>305338.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>142790.423900</td>\n",
       "      <td>322686.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>134870.413000</td>\n",
       "      <td>303624.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>143046.673900</td>\n",
       "      <td>309097.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>144360.728300</td>\n",
       "      <td>314078.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>144909.847800</td>\n",
       "      <td>301767.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>132732.173900</td>\n",
       "      <td>342104.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>135555.413000</td>\n",
       "      <td>317023.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>127774.684800</td>\n",
       "      <td>365012.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>131659.760900</td>\n",
       "      <td>310432.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>124394.163000</td>\n",
       "      <td>290223.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>123876.184800</td>\n",
       "      <td>311433.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>125917.945700</td>\n",
       "      <td>300379.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>126702.608700</td>\n",
       "      <td>323041.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>119601.923900</td>\n",
       "      <td>295838.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>130557.282600</td>\n",
       "      <td>314266.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>129712.782600</td>\n",
       "      <td>302998.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>120014.228300</td>\n",
       "      <td>301636.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>116366.684800</td>\n",
       "      <td>292472.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>113314.108700</td>\n",
       "      <td>297139.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>112758.467400</td>\n",
       "      <td>299952.937500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3818, training_loss=293287.6998428497, metrics={'train_runtime': 274.6969, 'train_samples_per_second': 84223.74, 'train_steps_per_second': 334.915, 'total_flos': 4147332083951616.0, 'train_loss': 293287.6998428497, 'epoch': 83.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c82603",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = trainer.state.log_history\n",
    "df = pd.DataFrame(log_data)\n",
    "\n",
    "df_train = df[df['loss'].notna()][['epoch', 'loss']]\n",
    "df_eval = df[df['eval_loss'].notna()][['epoch', 'eval_loss']]\n",
    "\n",
    "final_df = pd.merge(df_train, df_eval, on=\"epoch\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b85a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.585352e+06</td>\n",
       "      <td>1.517284e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.615469e+05</td>\n",
       "      <td>7.996447e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.336539e+05</td>\n",
       "      <td>7.209687e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.558790e+05</td>\n",
       "      <td>6.551591e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.178511e+05</td>\n",
       "      <td>6.069545e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79.0</td>\n",
       "      <td>1.297128e+05</td>\n",
       "      <td>3.029985e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1.200142e+05</td>\n",
       "      <td>3.016360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81.0</td>\n",
       "      <td>1.163667e+05</td>\n",
       "      <td>2.924721e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82.0</td>\n",
       "      <td>1.133141e+05</td>\n",
       "      <td>2.971394e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83.0</td>\n",
       "      <td>1.127585e+05</td>\n",
       "      <td>2.999529e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch          loss     eval_loss\n",
       "0     1.0  1.585352e+06  1.517284e+06\n",
       "1     2.0  9.615469e+05  7.996447e+05\n",
       "2     3.0  8.336539e+05  7.209687e+05\n",
       "3     4.0  7.558790e+05  6.551591e+05\n",
       "4     5.0  7.178511e+05  6.069545e+05\n",
       "..    ...           ...           ...\n",
       "78   79.0  1.297128e+05  3.029985e+05\n",
       "79   80.0  1.200142e+05  3.016360e+05\n",
       "80   81.0  1.163667e+05  2.924721e+05\n",
       "81   82.0  1.133141e+05  2.971394e+05\n",
       "82   83.0  1.127585e+05  2.999529e+05\n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.to_csv(os.path.join(LOG_DIR, f\"pretrain_{loss_name}_model{}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21441498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- '실제 MAE' (Unscaled) 계산 시작 ---\n",
      "--- 훈련된 모델의 '실제 MAE' (Unscaled) ---\n",
      "Final Real MAE: 4368.487526203752\n"
     ]
    }
   ],
   "source": [
    "# 1. 훈련된 베스트 모델 로드\n",
    "best_model_path = \"./pretrained/MAE/checkpoint-17376\" # 베스트 모델 경로\n",
    "best_model = PatchTSTForPrediction.from_pretrained(best_model_path)\n",
    "best_model.eval()\n",
    "\n",
    "# 2. test_dataset으로 DataLoader 생성\n",
    "# (test_dataset은 'past_values'와 'future_values'를 포함하는 Hf Dataset)\n",
    "test_dataset.set_format(type='torch', columns=['past_values', 'future_values'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "total_real_mae = 0\n",
    "total_samples = 0\n",
    "\n",
    "print(\"--- '실제 MAE' (Unscaled) 계산 시작 ---\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # 모델의 forward pass 실행\n",
    "        outputs = best_model(\n",
    "            past_values=batch['past_values'],\n",
    "            # [참고] 'future_values'를 전달하지 않아도 예측은 가능합니다.\n",
    "            # (전달하면 outputs.loss도 계산해줌)\n",
    "        )\n",
    "\n",
    "        if isinstance(outputs.prediction_outputs, tuple):\n",
    "            unscaled_preds = outputs.prediction_outputs[0]\n",
    "        else:\n",
    "            unscaled_preds = outputs.prediction_outputs # (튜플이 아닌 경우 대비)\n",
    "\n",
    "        unscaled_labels = batch['future_values']\n",
    "        \n",
    "        #    (배치 전체의 평균 MAE)\n",
    "        real_mae = torch.abs(unscaled_preds - unscaled_labels).mean()\n",
    "        \n",
    "        # (정확한 계산을 위해 배치 크기 가중 평균)\n",
    "        total_real_mae += real_mae.item() * len(batch['future_values'])\n",
    "        total_samples += len(batch['future_values'])\n",
    "\n",
    "final_real_mae = total_real_mae / total_samples\n",
    "print(f\"--- 훈련된 모델의 '실제 MAE' (Unscaled) ---\")\n",
    "print(f\"Final Real MAE: {final_real_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a32c038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 22:57:34.252156: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tbparse import SummaryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16d51789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 파일이 있는 폴더 경로\n",
    "log_dir = \"./logs/events.out.tfevents.1761999330.cd0dd4fe3564.737145.0\"\n",
    "\n",
    "# 1. 로그 폴더를 읽습니다.\n",
    "reader = SummaryReader(log_dir)\n",
    "\n",
    "# 2. 스칼라 값(loss 등)을 DataFrame으로 변환합니다.\n",
    "df_scalars = reader.scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39663eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 훈련된 모델의 '실제 MAE' (Unscaled) ---\n",
      "Final Real MAE: 360.81136456037126\n"
     ]
    }
   ],
   "source": [
    "# 훈련된 베스트 모델 로드\n",
    "best_model_path = \"./pretrained/checkpoint-12851\" # 베스트 모델 경로\n",
    "best_model = PatchTSTForPrediction.from_pretrained(best_model_path)\n",
    "best_model.eval()\n",
    "\n",
    "# 2. test_dataset으로 DataLoader 생성\n",
    "# (test_dataset은 'past_values'와 'future_values'를 포함하는 Hf Dataset)\n",
    "test_dataset.set_format(type='torch', columns=['past_values', 'future_values'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "total_real_mae = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # 모델의 forward pass 실행\n",
    "        outputs = best_model(\n",
    "            past_values=batch['past_values']   ## attribute\n",
    "        )\n",
    "\n",
    "        if isinstance(outputs.prediction_outputs, tuple):\n",
    "            unscaled_preds = outputs.prediction_outputs[0]\n",
    "        else:\n",
    "            unscaled_preds = outputs.prediction_outputs # (튜플이 아닌 경우 대비)\n",
    "\n",
    "        unscaled_labels = batch['future_values']    ## label\n",
    "        \n",
    "        #    (배치 전체의 평균 MAE)\n",
    "        real_mae = torch.abs(unscaled_preds - unscaled_labels).mean()\n",
    "        \n",
    "        # (정확한 계산을 위해 배치 크기 가중 평균)\n",
    "        total_real_mae += real_mae.item() * len(batch['future_values'])\n",
    "        total_samples += len(batch['future_values'])\n",
    "\n",
    "final_real_mae = total_real_mae / total_samples\n",
    "print(f\"--- 훈련된 모델의 '실제 MAE' (Unscaled) ---\")\n",
    "print(f\"Final Real MAE: {final_real_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d671b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 훈련된 모델의 '실제 MSE' (Unscaled) ---\n",
      "Final Real MSE: 697501.4553393184\n"
     ]
    }
   ],
   "source": [
    "total_real_mse = 0\n",
    "total_samples = 0\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # 모델의 forward pass 실행\n",
    "        outputs = best_model(\n",
    "            past_values=batch['past_values']   ## attribute\n",
    "        )\n",
    "\n",
    "        if isinstance(outputs.prediction_outputs, tuple):\n",
    "            unscaled_preds = outputs.prediction_outputs[0]\n",
    "        else:\n",
    "            unscaled_preds = outputs.prediction_outputs # (튜플이 아닌 경우 대비)\n",
    "\n",
    "        unscaled_labels = batch['future_values']    ## label\n",
    "        \n",
    "        real_mse = loss_fn(unscaled_preds, unscaled_labels)\n",
    "        \n",
    "        # (정확한 계산을 위해 배치 크기 가중 평균)\n",
    "        total_real_mae += real_mse.item() * len(batch['future_values'])\n",
    "        total_samples += len(batch['future_values'])\n",
    "\n",
    "final_real_mae = total_real_mae / total_samples\n",
    "print(f\"--- 훈련된 모델의 '실제 MSE' (Unscaled) ---\")\n",
    "print(f\"Final Real MSE: {final_real_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115446e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "835.1655257129082"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_real_mae**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a37e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_preds = outputs.prediction_outputs\n",
    "loss = torch.nn.MSELoss()(unscaled_preds, unscaled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8129688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(222041.7812, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f33344af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(4472.5435)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ad14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea6f66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"./pretrained/checkpoint-12851\" # 베스트 모델 경로\n",
    "best_model = PatchTSTForPrediction.from_pretrained(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61f21104",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_head = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(start_dim=2, end_dim=-1),\n",
    "    torch.nn.Linear(1280, 128),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(64, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d960014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = torch.nn.Sequential(\n",
    "    best_model.model,\n",
    "    MLP_head\n",
    ")\n",
    "optimizr = torch.optim.Adam(model_instance.parameters(), lr = 1e-6)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join('saved_models', f'model_{lossf}_{i}.h5')\n",
    "base_loaded = PatchTSTForPrediction.from_pretrained(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d70e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience = 10,\n",
    "    early_stopping_threshold = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53035eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
