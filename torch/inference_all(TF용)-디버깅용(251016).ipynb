{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c11cfb-e560-43ce-a5c1-2d642e7c641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import *\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c686d7b3-89ea-4342-8c02-99c6e1376f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/TSTF/torch\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a6a690-98f2-4d0b-8195-3e21c8876ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 파일 검색 디버깅 ---\n",
      "검색 중인 폴더: resulttf/test/\n",
      "폴더 안의 모든 파일: ['trTFMLP_coin_mase_pred.csv', 'trTFMLP_coin_mse_pred.csv', 'trTFMLP_coin_mae_pred.csv', 'trTFMLP_coin_smape_pred.csv', 'trTFMLP_coin_mape_pred.csv']\n",
      "찾고 있는 파일 시작 부분(prefix): 'trTFMLP_coin'\n",
      "--- 디버깅 끝 ---\n",
      "\n",
      "INFO (iter 0): Median Ensemble RMSE = 3.64152\n",
      "INFO: Median breakdown for iter 0 saved.\n",
      "INFO (iter 0): BOLT (beta=1) RMSE = 3.63317\n",
      "INFO: BOLT breakdown for beta=1 saved.\n",
      "INFO (iter 0): BOLT (beta=3) RMSE = 3.63113\n",
      "INFO: BOLT breakdown for beta=3 saved.\n",
      "INFO (iter 0): BOLT (beta=5) RMSE = 3.63122\n",
      "INFO: BOLT breakdown for beta=5 saved.\n",
      "--------------------\n",
      "\n",
      "===== Aggregating results across all 50 iterations and creating final reports =====\n",
      "\n",
      "Final Performance Summary (Mean over 50 iterations):\n",
      "            mean       std          mean(std)\n",
      "BOLT    3.631227  0.002300  3.63123 (0.00230)\n",
      "Median  3.641952  0.002559  3.64195 (0.00256)\n",
      "INV     3.667214  0.002999  3.66721 (0.00300)\n",
      "Mean    3.765061  0.043920  3.76506 (0.04392)\n",
      "\n",
      "===== Generating AVERAGE breakdown files over 50 iterations... =====\n",
      "\n",
      "Average Median RMSE (for breakdown file): 3.64096\n",
      "INFO: Average Median breakdown saved.\n",
      "Average BOLT (beta=1) RMSE (for breakdown file): 3.63232\n",
      "INFO: Average BOLT (beta=1) breakdown saved.\n",
      "Average BOLT (beta=3) RMSE (for breakdown file): 3.63019\n",
      "INFO: Average BOLT (beta=3) breakdown saved.\n",
      "Average BOLT (beta=5) RMSE (for breakdown file): 3.63028\n",
      "INFO: Average BOLT (beta=5) breakdown saved.\n",
      "\n",
      "===== All processing finished. =====\n"
     ]
    }
   ],
   "source": [
    "data = ['coin']\n",
    "model_name = 'trTFMLP'\n",
    "num = 100    # Model k per loss\n",
    "\n",
    "for d in range(len(data)):\n",
    "    #############################################################################################\n",
    "    target_X= pd.read_csv(f\"../data/{data[d]}/train_input_7.csv\").iloc[:,1:].values.astype(np.float32)\n",
    "    target_y =pd.read_csv(f\"../data/{data[d]}/train_output_7.csv\").iloc[:,1:].values.astype(np.float32)\n",
    "    \n",
    "    \n",
    "    target_X_val= target_X[-round(target_X.shape[0]*0.2):,:].astype(np.float32)\n",
    "    target_y_val =target_y[-round(target_y.shape[0]*0.2):].astype(np.float32)\n",
    "    \n",
    "    \n",
    "    target_X = target_X[:-round(target_X.shape[0]*0.2),:].astype(np.float32)\n",
    "    target_y = target_y[:-round(target_y.shape[0]*0.2)].astype(np.float32)\n",
    "    test_X= pd.read_csv(f\"../data/{data[d]}/val_input_7.csv\").iloc[:,1:].values.astype(np.float32)\n",
    "    test_y =pd.read_csv(f\"../data/{data[d]}/val_output_7.csv\").iloc[:,1:].values.astype(np.float32)\n",
    "    \n",
    "    \n",
    "    #############################################################################################\n",
    "    \n",
    "    folder_path = 'resulttf/test/'\n",
    "    folder_path2 = 'resulttf/val/'\n",
    "    \n",
    "    all_files = os.listdir(folder_path)\n",
    "    all_files2 = os.listdir(folder_path2)\n",
    "    print(f\"--- 파일 검색 디버깅 ---\")\n",
    "    print(f\"검색 중인 폴더: {folder_path}\")\n",
    "    print(f\"폴더 안의 모든 파일: {all_files}\")\n",
    "    search_prefix = f\"{model_name}_{data[d]}\"\n",
    "    print(f\"찾고 있는 파일 시작 부분(prefix): '{search_prefix}'\")\n",
    "    print(\"--- 디버깅 끝 ---\")\n",
    "    files = sorted([f for f in all_files if f.startswith(f\"{model_name}_{data[d]}\") and f.endswith(\"pred.csv\")])\n",
    "    dataframes = [pd.read_csv(os.path.join(folder_path, f)) for f in files]\n",
    "    \n",
    "    files2 = sorted([f for f in all_files2 if f.startswith(f\"{model_name}_{data[d]}\") and f.endswith(\"pred.csv\")])\n",
    "    dataframes2 = [pd.read_csv(os.path.join(folder_path2, f)) for f in files2]\n",
    "    \n",
    "    all=np.array([np.stack(dataframes[i].iloc[:,1:].values.reshape(num,-1, target_y.shape[1])) for i in range(len(dataframes))])#.reshape(num*5,-1,24)\n",
    "    all_val=np.array([np.stack(dataframes2[i].iloc[:,1:].values.reshape(num,-1, target_y.shape[1])) for i in range(len(dataframes2))])#.reshape(num*5,-1,24)\n",
    "    #############################################################################################\n",
    "    all_ens_lst, all_ens_rmse_lst = [], []\n",
    "    bolt_lst, bolt_rmse_lst        = [], []\n",
    "    \n",
    "    inv_lst, inv_rmse_lst          = [] , []        ### NEW: 역수 가중치 결과 저장용\n",
    "    mean_rmse_lst                  = []             ### NEW: mean 평가 지표 기록용\n",
    "\n",
    "    # 251015 ===== [ADD-INIT] 디버깅 수집 컨테이너 & 경로 =====\n",
    "    # 1) 손실별 test RMSE 수집\n",
    "    per_loss_test_rmse = {'MAE': [], 'MAPE': [], 'MASE': [], 'MSE': [], 'SMAPE': []}\n",
    "    \n",
    "    # 2) β 그리드 및 β별 가중치 저장 (각 부트스트랩에서의 weight 벡터 5개)\n",
    "    beta_grid = np.arange(1, 10.2, 0.2)  # 1.0 ~ 10.0 (step 0.2)\n",
    "    weights_by_beta = {float(np.round(b, 3)): [] for b in beta_grid}  # {beta: [w(5,)]}\n",
    "    \n",
    "    # 3) 각 부트스트랩에서 \"최적 β\"와 그때의 가중치/성능 기록\n",
    "    best_beta_rows = []  # dict(iter, beta, bolt_rmse, w_mae, w_mape, w_mase, w_mse, w_smape)\n",
    "    \n",
    "    # 4) 저장 경로 보장\n",
    "    os.makedirs('inference', exist_ok=True)\n",
    "\n",
    "    SAVE_BREAKDOWN_PER_ITER = False   # per-iter 저장 끄기(용량 절감)\n",
    "    samples = []                      # 각 iter에서 뽑은 모델 인덱스 저장\n",
    "    \n",
    "    p = 10\n",
    "    b = 50\n",
    "    np.random.seed(100)       ### NEW: mean 평가 지표 기록용\n",
    "\n",
    "    \n",
    "    for i in range(b):\n",
    "        # --------------------------------------------------------------\n",
    "        # 1) 무작위 인덱스 샘플링\n",
    "        #matrix = np.arange(100).reshape(10, 10)\n",
    "        nums1 = random.sample(range(num), k=p)\n",
    "        nums2 = random.sample(range(num), k=p)\n",
    "        nums3 = random.sample(range(num), k=p)\n",
    "        nums4 = random.sample(range(num), k=p)\n",
    "        nums5 = random.sample(range(num), k=p)\n",
    "\n",
    "        # ▼ 추가: 나중에 재현하려고 저장\n",
    "        samples.append((nums1, nums2, nums3, nums4, nums5))\n",
    "\n",
    "        #nums1 = matrix[i]\n",
    "        #nums2 = matrix[i]\n",
    "        #nums3 = matrix[i]\n",
    "        #nums4 = matrix[i]\n",
    "        #nums5 = matrix[i]\n",
    "        # --------------------------------------------------------------\n",
    "        # 2) all_Ens  (median 앙상블은 그대로)\n",
    "        score      = np.concatenate([all[0][nums1], all[1][nums2],\n",
    "                                       all[2][nums3], all[3][nums4],\n",
    "                                       all[4][nums5]], axis=0)\n",
    "        \n",
    "        all_ens    = np.median(score, axis=0).flatten()\n",
    "        all_ens_rmse = np.sqrt(mean_squared_error(test_y.flatten(), all_ens))\n",
    "        all_ens_lst.append(all_ens)\n",
    "        all_ens_rmse_lst.append(all_ens_rmse)\n",
    "\n",
    "        \n",
    "        # --- [순서 변경] Breakdown 생성을 위해 performance와 gd를 먼저 계산 ---\n",
    "        mae_val = np.median(all_val[0][nums1],axis=0).flatten()\n",
    "        mape_val = np.median(all_val[1][nums2],axis=0).flatten()\n",
    "        mase_val = np.median(all_val[2][nums3],axis=0).flatten()\n",
    "        mse_val = np.median(all_val[3][nums4],axis=0).flatten()\n",
    "        smape_val = np.median(all_val[4][nums5],axis=0).flatten()\n",
    "        \n",
    "        rmse_mae_val = np.sqrt(mean_squared_error(target_y_val.flatten(),mae_val))\n",
    "        rmse_mape_val = np.sqrt(mean_squared_error(target_y_val.flatten(),mape_val))\n",
    "        rmse_mase_val = np.sqrt(mean_squared_error(target_y_val.flatten(),mase_val))\n",
    "        rmse_mse_val = np.sqrt(mean_squared_error(target_y_val.flatten(),mse_val))\n",
    "        rmse_smape_val = np.sqrt(mean_squared_error(target_y_val.flatten(),smape_val))\n",
    "\n",
    "        performance = np.array([rmse_mae_val, rmse_mape_val,rmse_mase_val,rmse_mse_val,rmse_smape_val])\n",
    "\n",
    "        fin_pred_mae = np.median(all[0][nums1], axis=0).flatten()\n",
    "        fin_pred_mape = np.median(all[1][nums2], axis=0).flatten()\n",
    "        fin_pred_mase = np.median(all[2][nums3], axis=0).flatten()\n",
    "        fin_pred_mse = np.median(all[3][nums4], axis=0).flatten()\n",
    "        fin_pred_smape = np.median(all[4][nums5], axis=0).flatten()\n",
    "        gd = np.stack([fin_pred_mae, fin_pred_mape, fin_pred_mase, fin_pred_mse, fin_pred_smape], axis=0)\n",
    "\n",
    "        # (참고용) 손실별 test RMSE 수집\n",
    "        rmse_mae_test    = np.sqrt(mean_squared_error(test_y.flatten(),  fin_pred_mae))\n",
    "        rmse_mape_test   = np.sqrt(mean_squared_error(test_y.flatten(),  fin_pred_mape))\n",
    "        rmse_mase_test   = np.sqrt(mean_squared_error(test_y.flatten(),  fin_pred_mase))\n",
    "        rmse_mse_test    = np.sqrt(mean_squared_error(test_y.flatten(),  fin_pred_mse))\n",
    "        rmse_smape_test  = np.sqrt(mean_squared_error(test_y.flatten(),  fin_pred_smape))\n",
    "        per_loss_test_rmse['MAE'].append(rmse_mae_test)\n",
    "        per_loss_test_rmse['MAPE'].append(rmse_mape_test)\n",
    "        per_loss_test_rmse['MASE'].append(rmse_mase_test)\n",
    "        per_loss_test_rmse['MSE'].append(rmse_mse_test)\n",
    "        per_loss_test_rmse['SMAPE'].append(rmse_smape_test)\n",
    "\n",
    "\n",
    "        # --- 이제 상세 Breakdown 생성 코드를 실행 ---\n",
    "        if i == 0:\n",
    "            y_true_flat = test_y.flatten()\n",
    "            num_timesteps = all_ens.shape[0]\n",
    "            loss_names = ['mae', 'mape', 'mase', 'mse', 'smape']\n",
    "            \n",
    "            # (1) Median 앙상블 Breakdown\n",
    "            iter0_median_rmse = np.sqrt(mean_squared_error(y_true_flat, all_ens))\n",
    "            print(f\"\\nINFO (iter 0): Median Ensemble RMSE = {iter0_median_rmse:.5f}\")\n",
    "            median_rows = []\n",
    "            for t in range(num_timesteps):\n",
    "                row = {'iter': i, 't': t, 'y_true': y_true_flat[t], 'median_pred': all_ens[t], 'squared_error': (y_true_flat[t] - all_ens[t])**2, 'overall_rmse': iter0_median_rmse}\n",
    "                for loss_idx, name in enumerate(loss_names):\n",
    "                    row[f'base_pred_{name}'] = gd[loss_idx, t]\n",
    "                median_rows.append(row)\n",
    "            pd.DataFrame(median_rows).to_csv(f'inference/{model_name}_{data[d]}_median_breakdown_rmse.csv', index=False)\n",
    "            print(f\"INFO: Median breakdown for iter 0 saved.\")\n",
    "\n",
    "            # (2) 특정 Beta(1, 3, 5) 값에 대한 BOLT 앙상블 Breakdown\n",
    "            for target_beta in [1, 3, 5]:\n",
    "                weights = np.exp(-target_beta * performance)\n",
    "                weights /= np.sum(weights)\n",
    "                ensemble_prediction = np.dot(weights, gd)\n",
    "                iter0_bolt_rmse = np.sqrt(mean_squared_error(y_true_flat, ensemble_prediction))\n",
    "                print(f\"INFO (iter 0): BOLT (beta={target_beta}) RMSE = {iter0_bolt_rmse:.5f}\")\n",
    "                bolt_rows = []\n",
    "                for t in range(num_timesteps):\n",
    "                    row = {'iter': i, 'beta': target_beta, 't': t, 'y_true': y_true_flat[t], 'ensemble_pred': ensemble_prediction[t], 'squared_error': (y_true_flat[t] - ensemble_prediction[t])**2, 'overall_rmse': iter0_bolt_rmse}\n",
    "                    for loss_idx, name in enumerate(loss_names):\n",
    "                        row[f'base_pred_{name}'] = gd[loss_idx, t]\n",
    "                        row[f'w_{name}'] = weights[loss_idx]\n",
    "                    bolt_rows.append(row)\n",
    "                pd.DataFrame(bolt_rows).to_csv(f'inference/{model_name}_{data[d]}_bolt_breakdown_beta_{target_beta}_rmse.csv', index=False)\n",
    "                print(f\"INFO: BOLT breakdown for beta={target_beta} saved.\")\n",
    "            print(\"-\" * 20)\n",
    "        \n",
    "        # --------------------------------------------------------------\n",
    "    \n",
    "        # --------------------------------------------------------------\n",
    "        # 4) mean 평가지표(다섯 RMSE의 평균) 기록  ### NEW\n",
    "        mean_rmse   = np.mean(score, axis=0).flatten()\n",
    "        all_mean_rmse = np.sqrt(mean_squared_error(test_y.flatten(), mean_rmse))\n",
    "        mean_rmse_lst.append(all_mean_rmse)\n",
    "    \n",
    "        bolt_rmse_lst_ = []\n",
    "        bolt = []\n",
    "\n",
    "        # 251015 ===== [ADD-BETA-PREP] β별 가중치 수집 준비 =====\n",
    "        weights_seq = []   # β 순서대로 weight(길이 5) 기록\n",
    "\n",
    "        for beta in np.arange(1,10.2,0.2):\n",
    "            #beta = 1 # 조정 파라미터\n",
    "            weights = np.exp(-beta * performance)\n",
    "            # gd 계산이 루프 밖으로 이동했으므로 여기서는 재정의할 필요 없음\n",
    "            \n",
    "            normalized_weights = weights / np.sum(weights)\n",
    "\n",
    "            # ===== [ADD-WEIGHTS-CAPTURE] β별 가중치 저장 =====\n",
    "            weights_seq.append(normalized_weights.copy())\n",
    "            weights_by_beta[float(np.round(beta, 3))].append(normalized_weights.copy())\n",
    "\n",
    "            # 각 모델의 예측값에 가중치를 부여하여 앙상블 예측 생성\n",
    "            ensemble_prediction = np.dot(normalized_weights, gd)\n",
    "            bolt.append(ensemble_prediction)\n",
    "            bolt_rmse=np.sqrt(mean_squared_error(test_y.flatten(),ensemble_prediction.flatten()))\n",
    "            bolt_rmse_lst_.append(bolt_rmse)\n",
    "            \n",
    "        \n",
    "        bolt_lst.append(bolt)\n",
    "        bolt_rmse_lst.append(bolt_rmse_lst_)\n",
    "        # 251015 ===== [ADD-BEST-BETA] 이 부트스트랩에서 최적 β 기록 =====\n",
    "        best_idx = int(np.argmin(bolt_rmse_lst_))\n",
    "        best_beta_val = float(np.round(beta_grid[best_idx], 3))\n",
    "        best_weights = weights_seq[best_idx]\n",
    "        best_bolt_rmse = bolt_rmse_lst_[best_idx]\n",
    "        best_beta_rows.append({\n",
    "            'iter': i,\n",
    "            'beta': best_beta_val,\n",
    "            'bolt_rmse': best_bolt_rmse,\n",
    "            'w_mae':   best_weights[0],\n",
    "            'w_mape':  best_weights[1],\n",
    "            'w_mase':  best_weights[2],\n",
    "            'w_mse':   best_weights[3],\n",
    "            'w_smape': best_weights[4],\n",
    "        })\n",
    "\n",
    "        best_ens_pred = bolt[best_idx].flatten()\n",
    "\n",
    "        show_idx = range(best_ens_pred.shape[0])  # <<<<< 모든 시점\n",
    "\n",
    "        dbg_rows = []\n",
    "        y_true_flat = test_y.flatten()  # 대응 GT\n",
    "        \n",
    "        for k in show_idx:\n",
    "            base_preds_k = gd[:, k]  # 길이 5: [MAE, MAPE, MASE, MSE, SMAPE]\n",
    "            recon = float(np.dot(best_weights, base_preds_k))\n",
    "            dbg_rows += [\n",
    "                {'iter': i, 'beta': best_beta_val, 't': k, 'loss': 'MAE',   'base_pred': base_preds_k[0], 'weight': best_weights[0], 'weighted': base_preds_k[0]*best_weights[0],\n",
    "                 'ensemble': best_ens_pred[k], 'reconstructed': recon, 'y_true': y_true_flat[k]},\n",
    "                {'iter': i, 'beta': best_beta_val, 't': k, 'loss': 'MAPE',  'base_pred': base_preds_k[1], 'weight': best_weights[1], 'weighted': base_preds_k[1]*best_weights[1],\n",
    "                 'ensemble': best_ens_pred[k], 'reconstructed': recon, 'y_true': y_true_flat[k]},\n",
    "                {'iter': i, 'beta': best_beta_val, 't': k, 'loss': 'MASE',  'base_pred': base_preds_k[2], 'weight': best_weights[2], 'weighted': base_preds_k[2]*best_weights[2],\n",
    "                 'ensemble': best_ens_pred[k], 'reconstructed': recon, 'y_true': y_true_flat[k]},\n",
    "                {'iter': i, 'beta': best_beta_val, 't': k, 'loss': 'MSE',   'base_pred': base_preds_k[3], 'weight': best_weights[3], 'weighted': base_preds_k[3]*best_weights[3],\n",
    "                 'ensemble': best_ens_pred[k], 'reconstructed': recon, 'y_true': y_true_flat[k]},\n",
    "                {'iter': i, 'beta': best_beta_val, 't': k, 'loss': 'SMAPE', 'base_pred': base_preds_k[4], 'weight': best_weights[4], 'weighted': base_preds_k[4]*best_weights[4],\n",
    "                 'ensemble': best_ens_pred[k], 'reconstructed': recon, 'y_true': y_true_flat[k]},\n",
    "            ]\n",
    "        if SAVE_BREAKDOWN_PER_ITER:\n",
    "            # CSV로 누적 append 저장 (파일 없으면 헤더 포함)\n",
    "            dbg_path = f'inference/{model_name}_{data[d]}_value_weight_breakdown.csv'\n",
    "            exists = os.path.exists(dbg_path)\n",
    "            pd.DataFrame(dbg_rows).to_csv(dbg_path, mode='a', header=not exists, index=False)\n",
    "            print(\n",
    "            f\"[iter {i}] best β={best_beta_val:.3f} | BOLT_RMSE={best_bolt_rmse:.6f} | \"\n",
    "            f\"weights(MAE,MAPE,MASE,MSE,SMAPE)=\"\n",
    "            f\"({best_weights[0]:.4f}, {best_weights[1]:.4f}, {best_weights[2]:.4f}, {best_weights[3]:.4f}, {best_weights[4]:.4f})\"\n",
    "            )\n",
    "        # --------------------------------------------------------------\n",
    "        # 7) **역수 가중치 앙상블** ### NEW\n",
    "        inv_weights   = 1.0 / performance\n",
    "        inv_weights  /= np.sum(inv_weights)         # 정규화\n",
    "    \n",
    "        ens_pred_inv  = np.dot(inv_weights, gd)\n",
    "        inv_lst.append(ens_pred_inv)\n",
    "    \n",
    "        inv_rmse      = np.sqrt(mean_squared_error(test_y.flatten(),\n",
    "                                                  ens_pred_inv.flatten()))\n",
    "        inv_rmse_lst.append(inv_rmse)\n",
    "    \n",
    "# ============================ ▼▼▼ [최종] 평균 기반 Breakdown 생성 및 요약 코드 ▼▼▼ ============================\n",
    "\n",
    "print(\"\\n===== Aggregating results across all 50 iterations and creating final reports =====\")\n",
    "\n",
    "# --- 1. 최종 성능 요약 (기존과 동일한 방식) ---\n",
    "bolt_results = np.array(bolt_rmse_lst)\n",
    "summary = pd.DataFrame({\n",
    "    'BOLT': np.min(bolt_results, axis=1),\n",
    "    'Median': all_ens_rmse_lst,\n",
    "    'INV': inv_rmse_lst,\n",
    "    'Mean': mean_rmse_lst\n",
    "})\n",
    "summary.to_csv(f'inference/{model_name}_{data[d]}_summary_rmse.csv')\n",
    "\n",
    "final_report_df = summary.describe().T[['mean', 'std']]\n",
    "final_report_df['mean(std)'] = final_report_df.apply(lambda r: f\"{r['mean']:.5f} ({r['std']:.5f})\", axis=1)\n",
    "pd.DataFrame(final_report_df['mean(std)']).T.to_csv(f'{model_name}_{data[d]}_result_ensemble_rmse.csv')\n",
    "print(\"\\nFinal Performance Summary (Mean over 50 iterations):\")\n",
    "print(final_report_df)\n",
    "\n",
    "\n",
    "# --- 2. 평균 Breakdown 생성을 위한 데이터 집계 ---\n",
    "print(\"\\n===== Generating AVERAGE breakdown files over 50 iterations... =====\")\n",
    "\n",
    "# 50번 반복 동안의 모든 예측, 가중치 등을 저장할 리스트\n",
    "median_preds_50iters, gd_50iters = [], []\n",
    "bolt_preds_b1, bolt_preds_b3, bolt_preds_b5 = [], [], []\n",
    "weights_b1, weights_b3, weights_b5 = [], [], []\n",
    "\n",
    "# samples 리스트를 사용하여 50번의 실험을 동일하게 재구성\n",
    "for i in range(b):\n",
    "    nums1, nums2, nums3, nums4, nums5 = samples[i]\n",
    "\n",
    "    # 기본 예측값(gd)\n",
    "    fin_pred_mae   = np.median(all[0][nums1], axis=0).flatten()\n",
    "    fin_pred_mape  = np.median(all[1][nums2], axis=0).flatten()\n",
    "    fin_pred_mase  = np.median(all[2][nums3], axis=0).flatten()\n",
    "    fin_pred_mse   = np.median(all[3][nums4], axis=0).flatten()\n",
    "    fin_pred_smape = np.median(all[4][nums5], axis=0).flatten()\n",
    "    gd = np.stack([fin_pred_mae, fin_pred_mape, fin_pred_mase, fin_pred_mse, fin_pred_smape], axis=0)\n",
    "    gd_50iters.append(gd)\n",
    "    \n",
    "    # Median 예측값\n",
    "    score = np.concatenate([all[0][nums1], all[1][nums2], all[2][nums3], all[3][nums4], all[4][nums5]], axis=0)\n",
    "    median_preds_50iters.append(np.median(score, axis=0).flatten())\n",
    "\n",
    "    # BOLT 예측 및 가중치 계산을 위한 성능(performance) 값\n",
    "    mae_val   = np.median(all_val[0][nums1], axis=0).flatten()\n",
    "    mape_val  = np.median(all_val[1][nums2], axis=0).flatten()\n",
    "    mase_val  = np.median(all_val[2][nums3], axis=0).flatten()\n",
    "    mse_val   = np.median(all_val[3][nums4], axis=0).flatten()\n",
    "    smape_val = np.median(all_val[4][nums5], axis=0).flatten()\n",
    "    rmse_mae_val   = np.sqrt(mean_squared_error(target_y_val.flatten(), mae_val))\n",
    "    rmse_mape_val  = np.sqrt(mean_squared_error(target_y_val.flatten(), mape_val))\n",
    "    rmse_mase_val  = np.sqrt(mean_squared_error(target_y_val.flatten(), mase_val))\n",
    "    rmse_mse_val   = np.sqrt(mean_squared_error(target_y_val.flatten(), mse_val))\n",
    "    rmse_smape_val = np.sqrt(mean_squared_error(target_y_val.flatten(), smape_val))\n",
    "    performance = np.array([rmse_mae_val, rmse_mape_val, rmse_mase_val, rmse_mse_val, rmse_smape_val])\n",
    "\n",
    "    for target_beta in [1, 3, 5]:\n",
    "        w = np.exp(-target_beta * performance)\n",
    "        w /= np.sum(w)\n",
    "        pred = np.dot(w, gd)\n",
    "        if target_beta == 1:\n",
    "            weights_b1.append(w)\n",
    "            bolt_preds_b1.append(pred)\n",
    "        elif target_beta == 3:\n",
    "            weights_b3.append(w)\n",
    "            bolt_preds_b3.append(pred)\n",
    "        else: # beta == 5\n",
    "            weights_b5.append(w)\n",
    "            bolt_preds_b5.append(pred)\n",
    "\n",
    "# --- 3. 평균값 계산 ---\n",
    "avg_median_pred = np.mean(median_preds_50iters, axis=0)\n",
    "avg_gd = np.mean(gd_50iters, axis=0)\n",
    "avg_bolt_pred_b1, avg_weights_b1 = np.mean(bolt_preds_b1, axis=0), np.mean(weights_b1, axis=0)\n",
    "avg_bolt_pred_b3, avg_weights_b3 = np.mean(bolt_preds_b3, axis=0), np.mean(weights_b3, axis=0)\n",
    "avg_bolt_pred_b5, avg_weights_b5 = np.mean(bolt_preds_b5, axis=0), np.mean(weights_b5, axis=0)\n",
    "\n",
    "# --- 4. 평균 기반 Breakdown 파일 생성 ---\n",
    "y_true_flat = test_y.flatten()\n",
    "num_timesteps = y_true_flat.shape[0]\n",
    "loss_names = ['mae', 'mape', 'mase', 'mse', 'smape']\n",
    "\n",
    "# (1) Median Breakdown\n",
    "avg_median_rmse = np.sqrt(mean_squared_error(y_true_flat, avg_median_pred))\n",
    "print(f\"\\nAverage Median RMSE (for breakdown file): {avg_median_rmse:.5f}\")\n",
    "rows = []\n",
    "for t in range(num_timesteps):\n",
    "    # ★★★★★ 수정된 부분 1 ★★★★★\n",
    "    row = {'t': t, 'y_true': y_true_flat[t], 'avg_median_pred': avg_median_pred[t], 'squared_error': (y_true_flat[t] - avg_median_pred[t])**2, 'overall_rmse': avg_median_rmse}\n",
    "    for loss_idx, name in enumerate(loss_names):\n",
    "        row[f'avg_base_pred_{name}'] = avg_gd[loss_idx, t]\n",
    "    rows.append(row)\n",
    "pd.DataFrame(rows).to_csv(f'inference/{model_name}_{data[d]}_median_breakdown_AVG.csv', index=False)\n",
    "print(f\"INFO: Average Median breakdown saved.\")\n",
    "\n",
    "# (2) BOLT Breakdowns\n",
    "bolt_scenarios = {1: (avg_bolt_pred_b1, avg_weights_b1), 3: (avg_bolt_pred_b3, avg_weights_b3), 5: (avg_bolt_pred_b5, avg_weights_b5)}\n",
    "for beta, (avg_pred, avg_w) in bolt_scenarios.items():\n",
    "    avg_bolt_rmse = np.sqrt(mean_squared_error(y_true_flat, avg_pred))\n",
    "    print(f\"Average BOLT (beta={beta}) RMSE (for breakdown file): {avg_bolt_rmse:.5f}\")\n",
    "    rows = []\n",
    "    for t in range(num_timesteps):\n",
    "        # ★★★★★ 수정된 부분 2 ★★★★★\n",
    "        row = {'t': t, 'beta': beta, 'y_true': y_true_flat[t], 'avg_ensemble_pred': avg_pred[t], 'squared_error': (y_true_flat[t] - avg_pred[t])**2, 'overall_rmse': avg_bolt_rmse}\n",
    "        for loss_idx, name in enumerate(loss_names):\n",
    "            row[f'avg_base_pred_{name}'] = avg_gd[loss_idx, t]\n",
    "            row[f'avg_w_{name}'] = avg_w[loss_idx]\n",
    "        rows.append(row)\n",
    "    pd.DataFrame(rows).to_csv(f'inference/{model_name}_{data[d]}_bolt_breakdown_beta_{beta}_AVG.csv', index=False)\n",
    "    print(f\"INFO: Average BOLT (beta={beta}) breakdown saved.\")\n",
    "\n",
    "print(\"\\n===== All processing finished. =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe03a29-7248-4d83-b5a3-8d05241f7852",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['coin']\n",
    "rec = []\n",
    "for i in range(len(data)):\n",
    "    d= pd.read_csv(f'inference/{model_name}_{data[i]}_summary_rmse.csv').iloc[:,1:].describe().T.iloc[:,1:3].round(5)\n",
    "    d['mean(std)'] = d.apply(\n",
    "    lambda r: f\"{r['mean']:.5f} ({r['std']:.5f})\", axis=1)\n",
    "    \n",
    "    rec.append(d.loc[:,'mean(std)'])\n",
    "\n",
    "dfff = pd.DataFrame(rec).T\n",
    "\n",
    "dfff.columns = data\n",
    "dfff.to_csv(f'{model_name}_result_ensemble.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e96c26b-7a7c-463b-aec6-0e2b5b8bf690",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = pd.DataFrame(rec).T\n",
    "\n",
    "dfff.columns = data\n",
    "dfff.to_csv(f'{model_name}_result_ensemble.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3345040d-8269-4023-a2f7-198df0a05c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOLT</th>\n",
       "      <td>3.63123 (0.00230)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median</th>\n",
       "      <td>3.64195 (0.00256)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INV</th>\n",
       "      <td>3.66721 (0.00300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>3.76506 (0.04392)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     coin\n",
       "BOLT    3.63123 (0.00230)\n",
       "Median  3.64195 (0.00256)\n",
       "INV     3.66721 (0.00300)\n",
       "Mean    3.76506 (0.04392)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d6515dc-5803-4a44-91d5-4b35ab7b9a7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "[GLOBAL] best β=1.400 (argmin(a)*0.2=0.4) | mean weights(MAE,MAPE,MASE,MSE,SMAPE)=(0.2546, 0.0000, 0.4668, 0.2294, 0.0492)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOLT</th>\n",
       "      <th>Median</th>\n",
       "      <th>INV</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.430145</td>\n",
       "      <td>33.804334</td>\n",
       "      <td>21.927176</td>\n",
       "      <td>17.229689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.622853</td>\n",
       "      <td>1.849686</td>\n",
       "      <td>1.624610</td>\n",
       "      <td>1.357648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.514178</td>\n",
       "      <td>29.863431</td>\n",
       "      <td>15.670306</td>\n",
       "      <td>14.009819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.754363</td>\n",
       "      <td>32.603299</td>\n",
       "      <td>21.714360</td>\n",
       "      <td>16.241876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.082185</td>\n",
       "      <td>33.846544</td>\n",
       "      <td>22.313322</td>\n",
       "      <td>16.911413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.781210</td>\n",
       "      <td>35.201860</td>\n",
       "      <td>22.662740</td>\n",
       "      <td>18.419089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37.076003</td>\n",
       "      <td>37.608830</td>\n",
       "      <td>23.681403</td>\n",
       "      <td>20.515449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BOLT     Median        INV       Mean\n",
       "count  50.000000  50.000000  50.000000  50.000000\n",
       "mean   31.430145  33.804334  21.927176  17.229689\n",
       "std     5.622853   1.849686   1.624610   1.357648\n",
       "min    11.514178  29.863431  15.670306  14.009819\n",
       "25%    30.754363  32.603299  21.714360  16.241876\n",
       "50%    33.082185  33.846544  22.313322  16.911413\n",
       "75%    34.781210  35.201860  22.662740  18.419089\n",
       "max    37.076003  37.608830  23.681403  20.515449"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.min(np.array(bolt_rmse_lst),axis=0)\n",
    "\n",
    "print(np.argmin(a)*0.2)\n",
    "\n",
    "# 251015 정확한 β와, 그 β에서의 평균 weight(부트스트랩 전반)를 같이 출력\n",
    "idx_global_best = int(np.argmin(a))\n",
    "beta_grid = np.arange(1, 10.2, 0.2)\n",
    "beta_global_best = float(np.round(beta_grid[idx_global_best], 3))\n",
    "\n",
    "# 이 β에서 각 반복이 남긴 weight들을 평균내서 대표 weight를 보여줌\n",
    "# (weights_by_beta[beta]에는 각 iter의 weight 벡터가 들어있습니       다.)\n",
    "wlist = np.array(weights_by_beta[beta_global_best])  # shape: (b, 5)\n",
    "wmean = wlist.mean(axis=0)\n",
    "\n",
    "print(\n",
    "    f\"[GLOBAL] best β={beta_global_best:.3f} (argmin(a)*0.2={idx_global_best*0.2:.1f}) | \"\n",
    "    f\"mean weights(MAE,MAPE,MASE,MSE,SMAPE)=\"\n",
    "    f\"({wmean[0]:.4f}, {wmean[1]:.4f}, {wmean[2]:.4f}, {wmean[3]:.4f}, {wmean[4]:.4f})\"\n",
    ")\n",
    "\n",
    "summary= pd.DataFrame({'BOLT' : np.array(bolt_rmse_lst).T[np.argmin(a)],\n",
    "             'Median' : all_ens_rmse_lst,\n",
    "             'INV' :inv_rmse_lst,\n",
    "            'Mean': mean_rmse_lst})\n",
    "summary.to_csv(f'inference/{model_name}_{data[0]}_summary.csv')\n",
    "summary.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3b991e4-524b-4bf4-bfe4-9ee45e05f12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GLOBAL] best β=1.200 | mean weights(MAE,MAPE,MASE,MSE,SMAPE)=(0.2177, 0.0000, 0.4250, 0.3403, 0.0169)\n"
     ]
    }
   ],
   "source": [
    "# 20251015 ===== [ADD-SAVE-CSV] 요청한 디버깅 산출물 저장 =====\n",
    "# (1) 손실별 test RMSE 원자료/요약\n",
    "df_test_rmse = pd.DataFrame(per_loss_test_rmse)\n",
    "df_test_rmse.index.name = 'bootstrap_iter'\n",
    "df_test_rmse.to_csv(f'inference/{model_name}_{data[0]}_test_rmse_by_loss.csv', index=True)\n",
    "df_test_rmse.describe().round(6).to_csv(f'inference/{model_name}_{data[0]}_test_rmse_by_loss_summary.csv')\n",
    "\n",
    "# (2A) β×부트스트랩별 가중치 원자료 (long)\n",
    "rows = []\n",
    "for beta_val, Wlist in weights_by_beta.items():\n",
    "    for it, w in enumerate(Wlist):\n",
    "        rows.append({\n",
    "            'beta': beta_val,\n",
    "            'iter': it,\n",
    "            'w_mae':   w[0],\n",
    "            'w_mape':  w[1],\n",
    "            'w_mase':  w[2],\n",
    "            'w_mse':   w[3],\n",
    "            'w_smape': w[4],\n",
    "        })\n",
    "df_weights_raw = pd.DataFrame(rows)\n",
    "df_weights_raw.to_csv(f'inference/{model_name}_{data[0]}_weights_raw.csv', index=False)\n",
    "\n",
    "# (2B) β별 가중치 요약(평균/표준편차)\n",
    "df_weights_summary = (\n",
    "    df_weights_raw\n",
    "      .groupby('beta')[['w_mae','w_mape','w_mase','w_mse','w_smape']]\n",
    "      .agg(['mean','std'])\n",
    "      .round(6)\n",
    ")\n",
    "df_weights_summary.to_csv(f'inference/{model_name}_{data[0]}_weights_summary.csv')\n",
    "\n",
    "# (2C) 각 부트스트랩에서의 최적 β 및 그때의 가중치/성능\n",
    "pd.DataFrame(best_beta_rows).to_csv(f'inference/{model_name}_{data[0]}_best_beta_per_iter.csv', index=False)\n",
    "\n",
    "# === 251015 [ADD] GLOBAL best β에서의 평균 weight와, 샘플 시점 breakdown\n",
    "idx_global_best = int(np.argmin(a))\n",
    "beta_grid = np.arange(1, 10.2, 0.2)\n",
    "beta_global_best = float(np.round(beta_grid[idx_global_best], 3))\n",
    "\n",
    "# 부트스트랩 전반의 평균 weight\n",
    "wlist = np.array(weights_by_beta[beta_global_best])  # shape (b, 5)\n",
    "wmean = wlist.mean(axis=0)\n",
    "print(f\"[GLOBAL] best β={beta_global_best:.3f} | mean weights(MAE,MAPE,MASE,MSE,SMAPE)=\"\n",
    "      f\"({wmean[0]:.4f}, {wmean[1]:.4f}, {wmean[2]:.4f}, {wmean[3]:.4f}, {wmean[4]:.4f})\")\n",
    "\n",
    "# 원하시면, 전역 최적 β에서의 샘플 breakdown도 CSV로 저장 가능(평균 weight 사용)\n",
    "# (주의: 평균 weight는 한 iter의 실제 weight와 다르지만, 감 잡기용으로 충분)\n",
    "sample_k = 0  # 한 시점만 예시\n",
    "# gd는 iter마다 다르므로, 전역 샘플 breakdown은 의미가 애매할 수 있어 per-iter 쪽(A)로 보시는 걸 권장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b2c23d9-dccb-4b6a-aca2-ea8e7552b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[GLOBAL] Best result found at iter=22 with beta=1.400\n",
      "[GLOBAL] Corresponding RMSE: 11.514178\n",
      "[GLOBAL] breakdown saved → inference/trTFMLP_coin_value_weight_breakdown.csv\n"
     ]
    }
   ],
   "source": [
    "# ========== 전역 최적 β 1회만 breakdown 저장 ==========\n",
    "# bolt_rmse_lst: shape (b, n_beta)\n",
    "arr = np.array(bolt_rmse_lst)\n",
    "global_i, global_b = np.unravel_index(arr.argmin(), arr.shape)  # iter, beta 인덱스\n",
    "beta_global_best = float(np.round(beta_grid[global_b], 3))\n",
    "\n",
    "# 해당 iter에서 썼던 샘플 인덱스 회수\n",
    "nums1, nums2, nums3, nums4, nums5 = samples[global_i]\n",
    "\n",
    "# 해당 iter 기준으로 다시 예측/가중치 구성 (동일 방식)\n",
    "# test 예측 (각 손실별 median)\n",
    "fin_pred_mae   = np.median(all[0][nums1], axis=0).flatten()\n",
    "fin_pred_mape  = np.median(all[1][nums2], axis=0).flatten()\n",
    "fin_pred_mase  = np.median(all[2][nums3], axis=0).flatten()\n",
    "fin_pred_mse   = np.median(all[3][nums4], axis=0).flatten()\n",
    "fin_pred_smape = np.median(all[4][nums5], axis=0).flatten()\n",
    "\n",
    "# val 성능(=가중치 계산에 쓰는 성능)\n",
    "mae_val   = np.median(all_val[0][nums1], axis=0).flatten()\n",
    "mape_val  = np.median(all_val[1][nums2], axis=0).flatten()\n",
    "mase_val  = np.median(all_val[2][nums3], axis=0).flatten()\n",
    "mse_val   = np.median(all_val[3][nums4], axis=0).flatten()\n",
    "smape_val = np.median(all_val[4][nums5], axis=0).flatten()\n",
    "\n",
    "rmse_mae_val   = np.sqrt(mean_squared_error(target_y_val.flatten(), mae_val))\n",
    "rmse_mape_val  = np.sqrt(mean_squared_error(target_y_val.flatten(), mape_val))\n",
    "rmse_mase_val  = np.sqrt(mean_squared_error(target_y_val.flatten(), mase_val))\n",
    "rmse_mse_val   = np.sqrt(mean_squared_error(target_y_val.flatten(), mse_val))\n",
    "rmse_smape_val = np.sqrt(mean_squared_error(target_y_val.flatten(), smape_val))\n",
    "performance = np.array([rmse_mae_val, rmse_mape_val, rmse_mase_val, rmse_mse_val, rmse_smape_val])\n",
    "\n",
    "# 가중치(글로벌 최적 β)\n",
    "weights = np.exp(-beta_global_best * performance)\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "# gd (5, N) & 앙상블\n",
    "gd = np.vstack([\n",
    "    fin_pred_mae, fin_pred_mape, fin_pred_mase, fin_pred_mse, fin_pred_smape\n",
    "])\n",
    "best_ens_pred = np.dot(weights, gd).flatten()\n",
    "\n",
    "# 전역 최적 RMSE 계산 및 화면 출력\n",
    "y_true_flat = test_y.flatten()\n",
    "global_best_rmse = np.sqrt(mean_squared_error(y_true_flat, best_ens_pred))\n",
    "print(f\"\\n[GLOBAL] Best result found at iter={global_i} with beta={beta_global_best:.3f}\")\n",
    "print(f\"[GLOBAL] Corresponding RMSE: {global_best_rmse:.6f}\")\n",
    "\n",
    "# breakdown 저장 (이제 딱 1개 파일, 1개 β만 저장)\n",
    "dbg_rows = []\n",
    "for k in range(best_ens_pred.shape[0]):\n",
    "    base_preds_k = gd[:, k]\n",
    "    recon = float(np.dot(weights, base_preds_k))\n",
    "\n",
    "    # ✨✨✨ 수정된 부분 ✨✨✨\n",
    "    # 공통 데이터에 'squared_error'를 추가합니다.\n",
    "    common_data = {\n",
    "        'iter': global_i, 'beta': beta_global_best, 't': k,\n",
    "        'ensemble': best_ens_pred[k], 'reconstructed': recon, 'y_true': y_true_flat[k],\n",
    "        'squared_error': (y_true_flat[k] - best_ens_pred[k])**2, # 각 시점의 제곱 오차\n",
    "        'overall_rmse': global_best_rmse\n",
    "    }\n",
    "\n",
    "    dbg_rows += [\n",
    "        {**common_data, 'loss': 'MAE',   'base_pred': base_preds_k[0], 'weight': weights[0], 'weighted': base_preds_k[0]*weights[0]},\n",
    "        {**common_data, 'loss': 'MAPE',  'base_pred': base_preds_k[1], 'weight': weights[1], 'weighted': base_preds_k[1]*weights[1]},\n",
    "        {**common_data, 'loss': 'MASE',  'base_pred': base_preds_k[2], 'weight': weights[2], 'weighted': base_preds_k[2]*weights[2]},\n",
    "        {**common_data, 'loss': 'MSE',   'base_pred': base_preds_k[3], 'weight': weights[3], 'weighted': base_preds_k[3]*weights[3]},\n",
    "        {**common_data, 'loss': 'SMAPE', 'base_pred': base_preds_k[4], 'weight': weights[4], 'weighted': base_preds_k[4]*weights[4]},\n",
    "    ]\n",
    "\n",
    "dbg_path = f'inference/{model_name}_{data[0]}_value_weight_breakdown.csv'\n",
    "pd.DataFrame(dbg_rows).to_csv(dbg_path, index=False)\n",
    "print(f\"[GLOBAL] breakdown saved → {dbg_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18145c5a-9b2c-4e55-b89c-34383b58bc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performance at Specific Beta Values (RMSE) ---\n",
      "  Beta ≈ 1.0: Mean RMSE = 31.52304 (std = 5.66522)\n",
      "  Beta ≈ 3.0: Mean RMSE = 31.34087 (std = 5.57777)\n",
      "  Beta ≈ 5.0: Mean RMSE = 31.31971 (std = 5.56601)\n",
      "\n",
      "Specific Beta Performance Summary:\n",
      "   target_beta  closest_beta  mean_rmse  std_rmse\n",
      "0            1           1.0  31.523039  5.665223\n",
      "1            3           3.0  31.340869  5.577774\n",
      "2            5           5.0  31.319713  5.566011\n"
     ]
    }
   ],
   "source": [
    "# ============================ ▼▼▼ 추가할 코드 ▼▼▼ ============================\n",
    "# 2. 특정 Beta(1,3,5) 값에서의 평균 성능 확인\n",
    "print(\"\\n--- Performance at Specific Beta Values (RMSE) ---\")\n",
    "target_betas = [1, 3, 5]\n",
    "\n",
    "# beta_grid를 생성할 때 사용한 np.arange의 부동소수점 오차를 피하기 위해 컬럼명을 반올림합니다.\n",
    "beta_columns = [round(b, 2) for b in beta_grid]\n",
    "bolt_results_df = pd.DataFrame(np.array(bolt_rmse_lst), columns=beta_columns)\n",
    "\n",
    "beta_perf_summary = []\n",
    "for beta_val in target_betas:\n",
    "    # .values를 추가하여 Index 객체를 NumPy 배열로 변환\n",
    "    closest_beta_col = bolt_results_df.columns[np.abs(bolt_results_df.columns.values - beta_val).argmin()]\n",
    "    \n",
    "    mean_rmse = bolt_results_df[closest_beta_col].mean()\n",
    "    std_rmse = bolt_results_df[closest_beta_col].std()\n",
    "    \n",
    "    beta_perf_summary.append({\n",
    "        'target_beta': beta_val,\n",
    "        'closest_beta': closest_beta_col,\n",
    "        'mean_rmse': mean_rmse,\n",
    "        'std_rmse': std_rmse\n",
    "    })\n",
    "    print(f\"  Beta ≈ {closest_beta_col}: Mean RMSE = {mean_rmse:.5f} (std = {std_rmse:.5f})\")\n",
    "\n",
    "df_beta_summary = pd.DataFrame(beta_perf_summary)\n",
    "print(\"\\nSpecific Beta Performance Summary:\")\n",
    "print(df_beta_summary)\n",
    "# ============================ ▲▲▲ 추가할 코드 ▲▲▲ ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "620b0de1-6cd6-4e06-a2e8-633fe979b5c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m b135 \u001b[38;5;241m=\u001b[39m [] \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray(bolt_rmse_lst)[j]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10.2\u001b[39m,\u001b[38;5;241m0.2\u001b[39m) \u001b[38;5;241m==\u001b[39m n1[i])] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m)])\n\u001b[0;32m      5\u001b[0m     b135\u001b[38;5;241m.\u001b[39mappend(a)\n\u001b[0;32m      7\u001b[0m df135 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39marray(b135)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "n1  = [1,3,5]\n",
    "b135 = [] \n",
    "for j in range(1):\n",
    "    a = np.array([np.array(bolt_rmse_lst)[j].mean(axis=0)[np.where(np.arange(1,10.2,0.2) == n1[i])] for i in range(3)])\n",
    "    b135.append(a)\n",
    "\n",
    "df135 = pd.DataFrame(np.array(b135).reshape(1,3)).T\n",
    "df135.columns = data\n",
    "df135.T.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a2bb-686e-4924-ae55-47342c0819a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5fde5-1776-4ac5-b1ec-bf9b87aedec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d0b4b0-fc62-4057-bfd4-8b130a7ae466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259e06c-feed-42cc-bbb9-85a867d02e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736d545-33b7-4054-add2-0c4ea769ab9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb31e8-df31-429f-a203-d15ef7ff874b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a37386-4a9f-47bd-9d73-bb058c43f014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fdc9cd-864d-4adb-94d8-f9fbf1481ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e6dd7-2f60-4fb5-99aa-ea433ae93cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2bdf3f-c971-48f6-acd1-d18308af89f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d57142-df34-4e74-a8db-de1600417623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53c33e-1bb3-4e9f-94db-8bd4960febec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f382b-a1b3-40b3-bd2b-08d500aefd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d757e-5306-4834-bb93-5242d3fc42c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3659cfc-9b61-431c-9b96-2d0cff2b888b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b67156-c58a-49ef-a7e6-e6817c0c79f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056bcf7-0793-4553-b422-4f14435ab6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
