{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4991e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    PatchTSTConfig, PatchTSTForPrediction,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5fbee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"coin\"\n",
    "output_dir = \"./saved_models\"\n",
    "LOG_DIR = os.path.join('logstf', data)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "loss_name = \"mse\"\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7961096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## target domain\n",
    "target_X = pd.read_csv(f\"../data/{data}/train_input_7.csv\").iloc[:, 1:].values.astype(np.float32)\n",
    "\n",
    "np.random.seed(2)\n",
    "random_indices1 = np.random.choice(pd.read_csv(\"../data/M4_train.csv\").iloc[:, (1):].index,\n",
    "                                   size=target_X.shape[0] * 20, replace=True)\n",
    "\n",
    "X_data = pd.read_csv(\"../data/M4_train.csv\").iloc[:, 1 + (24 * 0):].loc[random_indices1].values.astype(np.float32)\n",
    "y_data = pd.read_csv(\"../data/M4_test.csv\").iloc[:, 1:].loc[random_indices1].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1bf8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d2836e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSTconfig = PatchTSTConfig(\n",
    "    num_input_channels = 1,\n",
    "    context_length = X_data.shape[1],\n",
    "    prediction_length = y_data.shape[1],\n",
    "\n",
    "    patch_length = 24,\n",
    "    patch_stride = 24,\n",
    "    d_model = 256,\n",
    "    num_attention_heads = 8,\n",
    "    num_hidden_layers = 8,\n",
    "    ffn_dim = 1024,\n",
    "    dropout = 0.2,\n",
    "    head_dropout = 0.2,\n",
    "    pooling_type = None,\n",
    "    channel_attention = False,\n",
    "    scaling = \"std\",\n",
    "    loss = loss_name,\n",
    "    pre_norm = True,\n",
    "    do_mask_input = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fa63645",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PatchTSTForPrediction(TSTconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91eb7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "select = np.random.choice(len(X_data), size=len(X_data), replace=True)\n",
    "X_bootstrap = X_data[select]\n",
    "y_bootstrap = y_data[select]\n",
    "\n",
    "val_split_index = int(len(X_bootstrap) * 0.8)\n",
    "X_train, X_valid = X_bootstrap[:val_split_index], X_bootstrap[val_split_index:]\n",
    "y_train, y_valid = y_bootstrap[:val_split_index], y_bootstrap[val_split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4812b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hf_dataset(x, y):\n",
    "    x_list = [s[..., np.newaxis] for s in x]    ## (N, 168) -> (N, 168, 1)\n",
    "    y_list = [s[..., np.newaxis] for s in y]    ## (N, 24) -> (N, 24, 1)\n",
    "\n",
    "    data_dict = {\n",
    "        \"past_values\": x_list,\n",
    "        \"future_values\": y_list\n",
    "    }\n",
    "\n",
    "    return Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bd3e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_hf_dataset(X_train, y_train)\n",
    "test_dataset = create_hf_dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "226c7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    overwrite_output_dir = True,\n",
    "    learning_rate = learning_rate,\n",
    "    num_train_epochs = 2000,\n",
    "    do_eval = True,\n",
    "    eval_strategy = \"epoch\",\n",
    "    per_device_train_batch_size = 256,\n",
    "    per_device_eval_batch_size = 256,\n",
    "    dataloader_num_workers = 16,\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    save_total_limit = 1,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_loss\",\n",
    "    greater_is_better = False,\n",
    "    label_names = [\"future_values\"]\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience = 15,\n",
    "    early_stopping_threshold = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "957e3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    callbacks = [early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "08a252b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3818' max='92000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3818/92000 04:31 < 1:44:41, 14.04 it/s, Epoch 83/2000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1712831.130400</td>\n",
       "      <td>1196681.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1043972.608700</td>\n",
       "      <td>806034.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>898464.260900</td>\n",
       "      <td>724837.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>805465.565200</td>\n",
       "      <td>679294.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>745685.739100</td>\n",
       "      <td>633064.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>719852.608700</td>\n",
       "      <td>606726.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>707913.173900</td>\n",
       "      <td>635188.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>657008.260900</td>\n",
       "      <td>604339.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>578306.695700</td>\n",
       "      <td>627974.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>527039.739100</td>\n",
       "      <td>545414.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>504722.130400</td>\n",
       "      <td>510349.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>456245.304300</td>\n",
       "      <td>532146.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>462883.173900</td>\n",
       "      <td>571683.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>481428.956500</td>\n",
       "      <td>608603.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>461279.347800</td>\n",
       "      <td>531286.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>416864.173900</td>\n",
       "      <td>500268.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>392766.652200</td>\n",
       "      <td>547255.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>383583.173900</td>\n",
       "      <td>543483.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>371927.173900</td>\n",
       "      <td>475383.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>365479.434800</td>\n",
       "      <td>511179.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>338220.217400</td>\n",
       "      <td>556433.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>333667.108700</td>\n",
       "      <td>462973.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>334709.021700</td>\n",
       "      <td>540219.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>333445.717400</td>\n",
       "      <td>551352.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>321788.456500</td>\n",
       "      <td>464347.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>309727.347800</td>\n",
       "      <td>551948.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>315003.934800</td>\n",
       "      <td>490280.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>297292.239100</td>\n",
       "      <td>526430.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>277914.804300</td>\n",
       "      <td>538772.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>283934.130400</td>\n",
       "      <td>460789.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>280749.195700</td>\n",
       "      <td>440156.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>272419.434800</td>\n",
       "      <td>500415.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>255234.434800</td>\n",
       "      <td>478879.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>268352.521700</td>\n",
       "      <td>449343.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>263591.500000</td>\n",
       "      <td>511156.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>254629.978300</td>\n",
       "      <td>447985.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>242092.087000</td>\n",
       "      <td>492743.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>250172.891300</td>\n",
       "      <td>450863.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>236221.087000</td>\n",
       "      <td>515092.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>238307.347800</td>\n",
       "      <td>444453.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>226891.934800</td>\n",
       "      <td>527758.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>224872.782600</td>\n",
       "      <td>451623.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>216597.021700</td>\n",
       "      <td>489462.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>221784.434800</td>\n",
       "      <td>502720.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>223919.065200</td>\n",
       "      <td>401532.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>217884.108700</td>\n",
       "      <td>414826.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>194565.521700</td>\n",
       "      <td>421986.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>209418.173900</td>\n",
       "      <td>466717.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>208228.934800</td>\n",
       "      <td>409693.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>198406.152200</td>\n",
       "      <td>380382.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>201108.500000</td>\n",
       "      <td>434437.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>205334.043500</td>\n",
       "      <td>403595.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>188157.587000</td>\n",
       "      <td>408187.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>189460.434800</td>\n",
       "      <td>424725.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>185444.521700</td>\n",
       "      <td>379525.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>184188.239100</td>\n",
       "      <td>394583.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>180489.282600</td>\n",
       "      <td>410897.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>178368.576100</td>\n",
       "      <td>468229.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>172863.782600</td>\n",
       "      <td>364918.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>171655.032600</td>\n",
       "      <td>392558.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>164869.217400</td>\n",
       "      <td>370715.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>166712.891300</td>\n",
       "      <td>422245.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>168829.565200</td>\n",
       "      <td>372118.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>158885.945700</td>\n",
       "      <td>387974.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>152341.130400</td>\n",
       "      <td>409071.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>163493.869600</td>\n",
       "      <td>389961.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>161451.913000</td>\n",
       "      <td>349100.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>164873.076100</td>\n",
       "      <td>338750.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>147985.380400</td>\n",
       "      <td>426626.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>153498.880400</td>\n",
       "      <td>375342.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>141644.500000</td>\n",
       "      <td>365934.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>145343.967400</td>\n",
       "      <td>381693.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>139685.043500</td>\n",
       "      <td>370816.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>143594.326100</td>\n",
       "      <td>355597.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>142325.728300</td>\n",
       "      <td>377987.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>141682.358700</td>\n",
       "      <td>361372.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>141431.945700</td>\n",
       "      <td>423112.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>142489.500000</td>\n",
       "      <td>384767.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>135673.673900</td>\n",
       "      <td>392649.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>132863.478300</td>\n",
       "      <td>381394.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>137172.500000</td>\n",
       "      <td>410554.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>130291.641300</td>\n",
       "      <td>353186.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>131414.152200</td>\n",
       "      <td>373794.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3818, training_loss=310956.45272393926, metrics={'train_runtime': 272.7735, 'train_samples_per_second': 84817.633, 'train_steps_per_second': 337.276, 'total_flos': 6164372611934208.0, 'train_loss': 310956.45272393926, 'epoch': 83.0})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eda8f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. test_dataset으로 DataLoader 생성\n",
    "# (test_dataset은 'past_values'와 'future_values'를 포함하는 Hf Dataset)\n",
    "test_dataset.set_format(type='torch', columns=['past_values', 'future_values'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "unscaled_preds = []\n",
    "unscaled_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # 모델의 forward pass 실행\n",
    "        outputs = trainer.model(\n",
    "            past_values=batch['past_values'].to(\"cuda:0\")\n",
    "        )\n",
    "\n",
    "        if isinstance(outputs.prediction_outputs, tuple):\n",
    "            unscaled_preds.append(outputs.prediction_outputs[0])\n",
    "        else:\n",
    "            unscaled_preds.append(outputs.prediction_outputs) # (튜플이 아닌 경우 대비)\n",
    "\n",
    "        unscaled_labels.append(batch['future_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d32e6a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE: 582.0230712890625\n",
      "test MAE: 248.49415588378906\n",
      "test SMAPE: 6.983912944793701\n"
     ]
    }
   ],
   "source": [
    "yyhat = torch.concat(unscaled_preds).to(\"cpu\")\n",
    "yy = torch.concat(unscaled_labels)\n",
    "\n",
    "print(f\"test RMSE: {torch.sqrt(mseLoss(yyhat, yy))}\")\n",
    "print(f\"test MAE: {maeLoss(yyhat, yy)}\")\n",
    "print(f\"test SMAPE: {smape(yy, yyhat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c82603",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 로그 파일 저장: train/test loss\n",
    "log_data = trainer.state.log_history\n",
    "df = pd.DataFrame(log_data)\n",
    "\n",
    "df_train = df[df['loss'].notna()][['epoch', 'loss']]\n",
    "df_eval = df[df['eval_loss'].notna()][['epoch', 'eval_loss']]\n",
    "\n",
    "final_df = pd.merge(df_train, df_eval, on=\"epoch\", how=\"outer\").assign(epoch = lambda _df: _df.epoch.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64b85a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(os.path.join(LOG_DIR, f\"pretrain_{loss_name}_model{2}.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47db16ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'metric_for_best_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Trainer' object has no attribute 'metric_for_best_model'"
     ]
    }
   ],
   "source": [
    "trainer.metric_for_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b71c2b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), os.path.join(output_dir, f\"model_{loss_name}_{1}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13a8374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model name setting\n",
    "checkpoint_folder = glob.glob(os.path.join(output_dir, \"checkpoint-*\"))[0]\n",
    "os.rename(checkpoint_folder, os.path.join(output_dir, f\"model_{loss_name}_{2}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "145ccf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df34a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "mseLoss = torch.nn.MSELoss()\n",
    "maeLoss = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "885dd4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = os.path.join(output_dir, f\"model_{loss_name}_{1}\")\n",
    "best_model = PatchTSTForPrediction.from_pretrained(best_model_path)\n",
    "best_model.eval()\n",
    "\n",
    "# 2. test_dataset으로 DataLoader 생성\n",
    "# (test_dataset은 'past_values'와 'future_values'를 포함하는 Hf Dataset)\n",
    "test_dataset.set_format(type='torch', columns=['past_values', 'future_values'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "unscaled_preds = []\n",
    "unscaled_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # 모델의 forward pass 실행\n",
    "        outputs = best_model(\n",
    "            past_values=batch['past_values']\n",
    "        )\n",
    "\n",
    "        if isinstance(outputs.prediction_outputs, tuple):\n",
    "            unscaled_preds.append(outputs.prediction_outputs[0])\n",
    "        else:\n",
    "            unscaled_preds.append(outputs.prediction_outputs) # (튜플이 아닌 경우 대비)\n",
    "\n",
    "        unscaled_labels.append(batch['future_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "760b26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyhat = torch.concat(unscaled_preds)\n",
    "yy = torch.concat(unscaled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc19dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(yy, yyhat):\n",
    "    numerator = 100*abs(yy - yyhat)\n",
    "    denominator = (abs(yy) + abs(yyhat))/2\n",
    "    smape = torch.mean(numerator / denominator)\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f4a05f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE: 538.7234497070312\n",
      "test MAE: 242.28775024414062\n",
      "test SMAPE: 6.946401119232178\n"
     ]
    }
   ],
   "source": [
    "print(f\"test RMSE: {torch.sqrt(mseLoss(yyhat, yy))}\")\n",
    "print(f\"test MAE: {maeLoss(yyhat, yy)}\")\n",
    "print(f\"test SMAPE: {smape(yy, yyhat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d59ad14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2364"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7182a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(output_dir, f\"model_{loss_name}_{1}.pth\"), weights_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9774aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
